{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W3/ungraded_lab/C2_W3_Lab_1_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bT0to3TL2q7H"
   },
   "source": [
    "# Ungraded Lab: Transfer Learning\n",
    "\n",
    "In this lab, you will see how you can use a pre-trained model to achieve good results even with a small training dataset. This is called _transfer learning_ and you do this by leveraging the trained layers of an existing model and adding your own layers to fit your application. For example, you can:\n",
    "\n",
    "1. just get the convolution layers of one model\n",
    "2. attach some dense layers onto it\n",
    "3. train just the dense network\n",
    "4. evaluate the results\n",
    "\n",
    "Doing this will allow you to save time building your application because you will essentially skip weeks of training time of very deep networks. You will just use the features it has learned and tweak it for your dataset. Let's see how these are done in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvrr8pLRzJMV"
   },
   "source": [
    "**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running the notebook on your local machine might result in some of the code blocks throwing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-12slkPL6_JH"
   },
   "source": [
    "## Setup the pretrained model\n",
    "\n",
    "You will need to prepare pretrained model and configure the layers that you need. For this exercise, you will use the convolution layers of the [InceptionV3](https://arxiv.org/abs/1512.00567) architecture as your base model. To do that, you need to:\n",
    "\n",
    "1. Set the input shape to fit your application. In this case. set it to `150x150x3` as you've been doing in the last few labs.\n",
    "\n",
    "2. Pick and freeze the convolution layers to take advantage of the features it has learned already.\n",
    "\n",
    "3. Add dense layers which you will train.\n",
    "\n",
    "Let's see how to do these in the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VqhFEK2Y-PK"
   },
   "source": [
    "First, in preparing the input to the model, you want to fetch the pretrained weights of the `InceptionV3` model and remove the fully connected layer at the end because you will be replacing it later. You will also specify the input shape that your model will accept. Lastly, you want to freeze the weights of these layers because they have been trained already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "base_path = '../../../data/models/'\n",
    "file_name = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "path = os.path.join(base_path, file_name)\n",
    "url = 'https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'  # without the -O\n",
    "\n",
    "# ensure path exists\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# download file\n",
    "response = requests.get(url)\n",
    "with open(path, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KsiBCpQ1VvPp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the weights file you downloaded into a variable\n",
    "#local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize the base model.\n",
    "# Set the input shape and remove the dense layers.\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, # Exclude final dense layers; used for feature extraction.\n",
    "                                weights = None)      # Do not load any pre-trained weights.\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "pre_trained_model.load_weights(path)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False  # Prevent the layers' weights from being updated during training.\n",
    "\n",
    "# ... or like this...but seems to have different behaviour; not confirmed to be equivalent\n",
    "#pre_trained_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y2rEnqFaa9k"
   },
   "source": [
    "You can see the summary of the model below. You can see that it is a very deep network. You can then select up to which point of the network you want to use. As Laurence showed in the exercise, you will use up to `mixed7` as your base model and add to that. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application. `mixed7` on the other hand will be more generalized and you can start with that for your application. After the exercise, feel free to modify and use other layers to see what the results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qeGP0Ust5kCR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)            (None, 74, 74, 32)   864         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 74, 74, 32)  96          ['conv2d_188[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_188 (Activation)    (None, 74, 74, 32)   0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)            (None, 72, 72, 32)   9216        ['activation_188[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 72, 72, 32)  96          ['conv2d_189[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_189 (Activation)    (None, 72, 72, 32)   0           ['batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)            (None, 72, 72, 64)   18432       ['activation_189[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 72, 72, 64)  192         ['conv2d_190[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_190 (Activation)    (None, 72, 72, 64)   0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)  0           ['activation_190[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)            (None, 35, 35, 80)   5120        ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 35, 35, 80)  240         ['conv2d_191[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_191 (Activation)    (None, 35, 35, 80)   0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)            (None, 33, 33, 192)  138240      ['activation_191[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 33, 33, 192)  576        ['conv2d_192[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_192 (Activation)    (None, 33, 33, 192)  0           ['batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_192[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 16, 16, 64)  192         ['conv2d_196[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_196 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)            (None, 16, 16, 48)   9216        ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_196[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 16, 16, 48)  144         ['conv2d_194[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 16, 16, 96)  288         ['conv2d_197[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_194 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " activation_197 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_18 (AverageP  (None, 16, 16, 192)  0          ['max_pooling2d_9[0][0]']        \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_194[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_197[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)            (None, 16, 16, 32)   6144        ['average_pooling2d_18[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 16, 16, 64)  192         ['conv2d_193[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 16, 16, 64)  192         ['conv2d_195[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 16, 16, 96)  288         ['conv2d_198[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 16, 16, 32)  96          ['conv2d_199[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_193 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " activation_195 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " activation_198 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " activation_199 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_193[0][0]',         \n",
      "                                                                  'activation_195[0][0]',         \n",
      "                                                                  'activation_198[0][0]',         \n",
      "                                                                  'activation_199[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 16, 16, 64)  192         ['conv2d_203[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)            (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_203[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 16, 16, 48)  144         ['conv2d_201[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 16, 16, 96)  288         ['conv2d_204[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_201 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_19 (AverageP  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_201[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_204[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)            (None, 16, 16, 64)   16384       ['average_pooling2d_19[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 16, 16, 64)  192         ['conv2d_200[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 16, 16, 64)  192         ['conv2d_202[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 16, 16, 96)  288         ['conv2d_205[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 16, 16, 64)  192         ['conv2d_206[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_200 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " activation_202 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_200[0][0]',         \n",
      "                                                                  'activation_202[0][0]',         \n",
      "                                                                  'activation_205[0][0]',         \n",
      "                                                                  'activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 16, 16, 64)  192         ['conv2d_210[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)            (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 16, 16, 48)  144         ['conv2d_208[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 16, 16, 96)  288         ['conv2d_211[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_20 (AverageP  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_208[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_211[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)            (None, 16, 16, 64)   18432       ['average_pooling2d_20[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 16, 16, 64)  192         ['conv2d_207[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 16, 16, 64)  192         ['conv2d_209[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 16, 16, 96)  288         ['conv2d_212[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 16, 16, 64)  192         ['conv2d_213[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_207[0][0]',         \n",
      "                                                                  'activation_209[0][0]',         \n",
      "                                                                  'activation_212[0][0]',         \n",
      "                                                                  'activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 16, 16, 64)  192         ['conv2d_215[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 16, 16, 96)  288         ['conv2d_216[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)            (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)            (None, 7, 7, 96)     82944       ['activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 7, 7, 384)   1152        ['conv2d_214[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 7, 7, 96)    288         ['conv2d_217[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 7, 7, 384)    0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 7, 7, 96)     0           ['batch_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_214[0][0]',         \n",
      "                                                                  'activation_217[0][0]',         \n",
      "                                                                  'max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 7, 7, 128)   384         ['conv2d_222[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_222[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 7, 7, 128)   384         ['conv2d_223[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 7, 7, 128)   384         ['conv2d_219[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 7, 7, 128)   384         ['conv2d_224[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 7, 7, 128)   384         ['conv2d_220[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 7, 7, 128)   384         ['conv2d_225[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_21 (AverageP  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_21[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 7, 7, 192)   576         ['conv2d_218[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 7, 7, 192)   576         ['conv2d_221[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 7, 7, 192)   576         ['conv2d_226[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 7, 7, 192)   576         ['conv2d_227[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_218[0][0]',         \n",
      "                                                                  'activation_221[0][0]',         \n",
      "                                                                  'activation_226[0][0]',         \n",
      "                                                                  'activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 7, 7, 160)   480         ['conv2d_232[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 7, 7, 160)   480         ['conv2d_233[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 7, 7, 160)   480         ['conv2d_229[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 7, 7, 160)   480         ['conv2d_234[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 7, 7, 160)   480         ['conv2d_230[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 7, 7, 160)   480         ['conv2d_235[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_22 (AverageP  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_22[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 7, 7, 192)   576         ['conv2d_228[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 7, 7, 192)   576         ['conv2d_231[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 7, 7, 192)   576         ['conv2d_236[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 7, 7, 192)   576         ['conv2d_237[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_228[0][0]',         \n",
      "                                                                  'activation_231[0][0]',         \n",
      "                                                                  'activation_236[0][0]',         \n",
      "                                                                  'activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 7, 7, 160)   480         ['conv2d_242[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 7, 7, 160)   480         ['conv2d_243[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 7, 7, 160)   480         ['conv2d_239[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_244 (Batch  (None, 7, 7, 160)   480         ['conv2d_244[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 7, 7, 160)   480         ['conv2d_240[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_245 (Batch  (None, 7, 7, 160)   480         ['conv2d_245[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_245[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_23 (AverageP  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_240[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_23[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 7, 7, 192)   576         ['conv2d_238[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 7, 7, 192)   576         ['conv2d_241[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_246 (Batch  (None, 7, 7, 192)   576         ['conv2d_246[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 7, 7, 192)   576         ['conv2d_247[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_238[0][0]',         \n",
      "                                                                  'activation_241[0][0]',         \n",
      "                                                                  'activation_246[0][0]',         \n",
      "                                                                  'activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 7, 7, 192)   576         ['conv2d_252[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_252[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 7, 7, 192)   576         ['conv2d_253[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_253[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_253[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 7, 7, 192)   576         ['conv2d_249[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 7, 7, 192)   576         ['conv2d_254[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_249[0][0]']\n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 7, 7, 192)   576         ['conv2d_250[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 7, 7, 192)   576         ['conv2d_255[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_24 (AverageP  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 7, 7, 192)   576         ['conv2d_248[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 7, 7, 192)   576         ['conv2d_251[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 7, 7, 192)   576         ['conv2d_256[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 7, 7, 192)   576         ['conv2d_257[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_251[0][0]']\n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_248[0][0]',         \n",
      "                                                                  'activation_251[0][0]',         \n",
      "                                                                  'activation_256[0][0]',         \n",
      "                                                                  'activation_257[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 7, 7, 192)   576         ['conv2d_260[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_260 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_260[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 7, 7, 192)   576         ['conv2d_261[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_261 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_258 (Batch  (None, 7, 7, 192)   576         ['conv2d_258[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 7, 7, 192)   576         ['conv2d_262[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_258 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " activation_262 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)            (None, 3, 3, 320)    552960      ['activation_258[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 3, 3, 192)    331776      ['activation_262[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 3, 3, 320)   960         ['conv2d_259[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 3, 3, 192)   576         ['conv2d_263[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_259 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_259[0][0]']\n",
      "                                                                                                  \n",
      " activation_263 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_259[0][0]',         \n",
      "                                                                  'activation_263[0][0]',         \n",
      "                                                                  'max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_268 (Batch  (None, 3, 3, 448)   1344        ['conv2d_268[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_268 (Activation)    (None, 3, 3, 448)    0           ['batch_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_268[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_265 (Batch  (None, 3, 3, 384)   1152        ['conv2d_265[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_269 (Batch  (None, 3, 3, 384)   1152        ['conv2d_269[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_265 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_265[0][0]']\n",
      "                                                                                                  \n",
      " activation_269 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_269[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_269[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_25 (AverageP  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_266 (Batch  (None, 3, 3, 384)   1152        ['conv2d_266[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_267 (Batch  (None, 3, 3, 384)   1152        ['conv2d_267[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 3, 3, 384)   1152        ['conv2d_270[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 3, 3, 384)   1152        ['conv2d_271[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 3, 3, 192)    245760      ['average_pooling2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 3, 3, 320)   960         ['conv2d_264[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_266 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " activation_267 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " activation_270 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " activation_271 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 3, 3, 192)   576         ['conv2d_272[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_264 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_266[0][0]',         \n",
      "                                                                  'activation_267[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 3, 3, 768)    0           ['activation_270[0][0]',         \n",
      "                                                                  'activation_271[0][0]']         \n",
      "                                                                                                  \n",
      " activation_272 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_264[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_4[0][0]',          \n",
      "                                                                  'activation_272[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)            (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 3, 3, 448)   1344        ['conv2d_277[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_277 (Activation)    (None, 3, 3, 448)    0           ['batch_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)            (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_277[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 3, 3, 384)   1152        ['conv2d_274[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 3, 3, 384)   1152        ['conv2d_278[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_274 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " activation_278 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_26 (AverageP  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)            (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 3, 3, 384)   1152        ['conv2d_275[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 3, 3, 384)   1152        ['conv2d_276[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_279 (Batch  (None, 3, 3, 384)   1152        ['conv2d_279[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_280 (Batch  (None, 3, 3, 384)   1152        ['conv2d_280[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)            (None, 3, 3, 192)    393216      ['average_pooling2d_26[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 3, 3, 320)   960         ['conv2d_273[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_275 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " activation_276 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " activation_279 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " activation_280 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_281 (Batch  (None, 3, 3, 192)   576         ['conv2d_281[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_273 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_275[0][0]',         \n",
      "                                                                  'activation_276[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 3, 3, 768)    0           ['activation_279[0][0]',         \n",
      "                                                                  'activation_280[0][0]']         \n",
      "                                                                                                  \n",
      " activation_281 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_281[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_273[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_5[0][0]',          \n",
      "                                                                  'activation_281[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jDmGO9tg5iPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "# Choose `mixed7` as the last layer of your base model\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXT9SDMK7Ioa"
   },
   "source": [
    "## Add dense layers for your classifier\n",
    "\n",
    "Next, you will add dense layers to your model. These will be the layers that you will train and is tasked with recognizing cats and dogs. You will add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer as well to regularize the output and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)            (None, 74, 74, 32)   864         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 74, 74, 32)  96          ['conv2d_188[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_188 (Activation)    (None, 74, 74, 32)   0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)            (None, 72, 72, 32)   9216        ['activation_188[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 72, 72, 32)  96          ['conv2d_189[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_189 (Activation)    (None, 72, 72, 32)   0           ['batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)            (None, 72, 72, 64)   18432       ['activation_189[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 72, 72, 64)  192         ['conv2d_190[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_190 (Activation)    (None, 72, 72, 64)   0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)  0           ['activation_190[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)            (None, 35, 35, 80)   5120        ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 35, 35, 80)  240         ['conv2d_191[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_191 (Activation)    (None, 35, 35, 80)   0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)            (None, 33, 33, 192)  138240      ['activation_191[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 33, 33, 192)  576        ['conv2d_192[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_192 (Activation)    (None, 33, 33, 192)  0           ['batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_192[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 16, 16, 64)  192         ['conv2d_196[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_196 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)            (None, 16, 16, 48)   9216        ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_196[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 16, 16, 48)  144         ['conv2d_194[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 16, 16, 96)  288         ['conv2d_197[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_194 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " activation_197 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_18 (AverageP  (None, 16, 16, 192)  0          ['max_pooling2d_9[0][0]']        \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_194[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_197[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)            (None, 16, 16, 32)   6144        ['average_pooling2d_18[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 16, 16, 64)  192         ['conv2d_193[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 16, 16, 64)  192         ['conv2d_195[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 16, 16, 96)  288         ['conv2d_198[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 16, 16, 32)  96          ['conv2d_199[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_193 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " activation_195 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " activation_198 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " activation_199 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_193[0][0]',         \n",
      "                                                                  'activation_195[0][0]',         \n",
      "                                                                  'activation_198[0][0]',         \n",
      "                                                                  'activation_199[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 16, 16, 64)  192         ['conv2d_203[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)            (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_203[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 16, 16, 48)  144         ['conv2d_201[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 16, 16, 96)  288         ['conv2d_204[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_201 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_19 (AverageP  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_201[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_204[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)            (None, 16, 16, 64)   16384       ['average_pooling2d_19[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 16, 16, 64)  192         ['conv2d_200[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 16, 16, 64)  192         ['conv2d_202[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 16, 16, 96)  288         ['conv2d_205[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 16, 16, 64)  192         ['conv2d_206[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_200 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " activation_202 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_200[0][0]',         \n",
      "                                                                  'activation_202[0][0]',         \n",
      "                                                                  'activation_205[0][0]',         \n",
      "                                                                  'activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 16, 16, 64)  192         ['conv2d_210[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)            (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 16, 16, 48)  144         ['conv2d_208[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 16, 16, 96)  288         ['conv2d_211[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_20 (AverageP  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_208[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_211[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)            (None, 16, 16, 64)   18432       ['average_pooling2d_20[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 16, 16, 64)  192         ['conv2d_207[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 16, 16, 64)  192         ['conv2d_209[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 16, 16, 96)  288         ['conv2d_212[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 16, 16, 64)  192         ['conv2d_213[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_207[0][0]',         \n",
      "                                                                  'activation_209[0][0]',         \n",
      "                                                                  'activation_212[0][0]',         \n",
      "                                                                  'activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 16, 16, 64)  192         ['conv2d_215[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 16, 16, 96)  288         ['conv2d_216[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)            (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)            (None, 7, 7, 96)     82944       ['activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 7, 7, 384)   1152        ['conv2d_214[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 7, 7, 96)    288         ['conv2d_217[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 7, 7, 384)    0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 7, 7, 96)     0           ['batch_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_214[0][0]',         \n",
      "                                                                  'activation_217[0][0]',         \n",
      "                                                                  'max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 7, 7, 128)   384         ['conv2d_222[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_222[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 7, 7, 128)   384         ['conv2d_223[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 7, 7, 128)   384         ['conv2d_219[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 7, 7, 128)   384         ['conv2d_224[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 7, 7, 128)   384         ['conv2d_220[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 7, 7, 128)   384         ['conv2d_225[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_21 (AverageP  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_21[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 7, 7, 192)   576         ['conv2d_218[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 7, 7, 192)   576         ['conv2d_221[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 7, 7, 192)   576         ['conv2d_226[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 7, 7, 192)   576         ['conv2d_227[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_218[0][0]',         \n",
      "                                                                  'activation_221[0][0]',         \n",
      "                                                                  'activation_226[0][0]',         \n",
      "                                                                  'activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 7, 7, 160)   480         ['conv2d_232[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 7, 7, 160)   480         ['conv2d_233[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 7, 7, 160)   480         ['conv2d_229[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 7, 7, 160)   480         ['conv2d_234[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 7, 7, 160)   480         ['conv2d_230[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 7, 7, 160)   480         ['conv2d_235[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_22 (AverageP  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_22[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 7, 7, 192)   576         ['conv2d_228[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 7, 7, 192)   576         ['conv2d_231[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 7, 7, 192)   576         ['conv2d_236[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 7, 7, 192)   576         ['conv2d_237[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_228[0][0]',         \n",
      "                                                                  'activation_231[0][0]',         \n",
      "                                                                  'activation_236[0][0]',         \n",
      "                                                                  'activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 7, 7, 160)   480         ['conv2d_242[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 7, 7, 160)   480         ['conv2d_243[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 7, 7, 160)   480         ['conv2d_239[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_244 (Batch  (None, 7, 7, 160)   480         ['conv2d_244[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 7, 7, 160)   480         ['conv2d_240[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_245 (Batch  (None, 7, 7, 160)   480         ['conv2d_245[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_245[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_23 (AverageP  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_240[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_23[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 7, 7, 192)   576         ['conv2d_238[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 7, 7, 192)   576         ['conv2d_241[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_246 (Batch  (None, 7, 7, 192)   576         ['conv2d_246[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 7, 7, 192)   576         ['conv2d_247[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_238[0][0]',         \n",
      "                                                                  'activation_241[0][0]',         \n",
      "                                                                  'activation_246[0][0]',         \n",
      "                                                                  'activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 7, 7, 192)   576         ['conv2d_252[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_252[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 7, 7, 192)   576         ['conv2d_253[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_253[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_253[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 7, 7, 192)   576         ['conv2d_249[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 7, 7, 192)   576         ['conv2d_254[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_249[0][0]']\n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 7, 7, 192)   576         ['conv2d_250[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 7, 7, 192)   576         ['conv2d_255[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_24 (AverageP  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 7, 7, 192)   576         ['conv2d_248[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 7, 7, 192)   576         ['conv2d_251[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 7, 7, 192)   576         ['conv2d_256[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 7, 7, 192)   576         ['conv2d_257[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_251[0][0]']\n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_248[0][0]',         \n",
      "                                                                  'activation_251[0][0]',         \n",
      "                                                                  'activation_256[0][0]',         \n",
      "                                                                  'activation_257[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 37632)        0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         38536192    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            1025        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "# Append the dense network to the base model\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "# Print the model summary. See your dense network connected at the end.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SAwTTkWr56uC"
   },
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYLGw_RO7Z_X"
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "Now you will prepare the dataset. This is basically the same code as the one you used in the data augmentation lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "O4s8HckqGlnb"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# !wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: c:\\wagon\\code\\tensorflow-1-public\\data\n"
     ]
    }
   ],
   "source": [
    "# Code that works locally\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "url = 'https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip'\n",
    "\n",
    "# Path to save the downloaded file\n",
    "base_path = '../../../data'\n",
    "file_name = 'cats_and_dogs_filtered.zip'\n",
    "local_zip = os.path.join(base_path, file_name)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open(local_zip, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(local_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(base_path)\n",
    "\n",
    "# Delete zip file\n",
    "os.remove(local_zip)\n",
    "\n",
    "# Check if files are extracted\n",
    "print(f\"Files extracted to: {os.path.abspath(base_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WOV8jON3c3Jv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Extract the archive\n",
    "# zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "# zip_ref.extractall(\"tmp/\")\n",
    "# zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "#base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "base_dir = os.path.join(base_path, 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') \n",
    "\n",
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') \n",
    "\n",
    "# Directory with validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') \n",
    "\n",
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m3S6AZb7h-B"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "With that, you can now train the model. You will do 20 epochs and plot the results afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 - 22s - loss: 0.3376 - accuracy: 0.8645 - val_loss: 0.1307 - val_accuracy: 0.9520 - 22s/epoch - 219ms/step\n",
      "Epoch 2/20\n",
      "100/100 - 9s - loss: 0.2092 - accuracy: 0.9160 - val_loss: 0.1512 - val_accuracy: 0.9420 - 9s/epoch - 94ms/step\n",
      "Epoch 3/20\n",
      "100/100 - 9s - loss: 0.2150 - accuracy: 0.9175 - val_loss: 0.1228 - val_accuracy: 0.9600 - 9s/epoch - 92ms/step\n",
      "Epoch 4/20\n",
      "100/100 - 9s - loss: 0.2107 - accuracy: 0.9180 - val_loss: 0.1067 - val_accuracy: 0.9660 - 9s/epoch - 93ms/step\n",
      "Epoch 5/20\n",
      "100/100 - 9s - loss: 0.1965 - accuracy: 0.9305 - val_loss: 0.0967 - val_accuracy: 0.9670 - 9s/epoch - 93ms/step\n",
      "Epoch 6/20\n",
      "100/100 - 9s - loss: 0.1792 - accuracy: 0.9340 - val_loss: 0.1021 - val_accuracy: 0.9680 - 9s/epoch - 91ms/step\n",
      "Epoch 7/20\n",
      "100/100 - 9s - loss: 0.1791 - accuracy: 0.9385 - val_loss: 0.1352 - val_accuracy: 0.9640 - 9s/epoch - 91ms/step\n",
      "Epoch 8/20\n",
      "100/100 - 9s - loss: 0.1605 - accuracy: 0.9420 - val_loss: 0.1043 - val_accuracy: 0.9660 - 9s/epoch - 92ms/step\n",
      "Epoch 9/20\n",
      "100/100 - 9s - loss: 0.1452 - accuracy: 0.9455 - val_loss: 0.1867 - val_accuracy: 0.9500 - 9s/epoch - 91ms/step\n",
      "Epoch 10/20\n",
      "100/100 - 9s - loss: 0.1744 - accuracy: 0.9385 - val_loss: 0.1138 - val_accuracy: 0.9710 - 9s/epoch - 93ms/step\n",
      "Epoch 11/20\n",
      "100/100 - 9s - loss: 0.1335 - accuracy: 0.9535 - val_loss: 0.1664 - val_accuracy: 0.9630 - 9s/epoch - 92ms/step\n",
      "Epoch 12/20\n",
      "100/100 - 9s - loss: 0.1590 - accuracy: 0.9505 - val_loss: 0.1068 - val_accuracy: 0.9720 - 9s/epoch - 91ms/step\n",
      "Epoch 13/20\n",
      "100/100 - 9s - loss: 0.1498 - accuracy: 0.9500 - val_loss: 0.1349 - val_accuracy: 0.9650 - 9s/epoch - 92ms/step\n",
      "Epoch 14/20\n",
      "100/100 - 9s - loss: 0.1433 - accuracy: 0.9515 - val_loss: 0.1349 - val_accuracy: 0.9610 - 9s/epoch - 93ms/step\n",
      "Epoch 15/20\n",
      "100/100 - 9s - loss: 0.1420 - accuracy: 0.9480 - val_loss: 0.1220 - val_accuracy: 0.9650 - 9s/epoch - 92ms/step\n",
      "Epoch 16/20\n",
      "100/100 - 9s - loss: 0.1270 - accuracy: 0.9555 - val_loss: 0.1410 - val_accuracy: 0.9670 - 9s/epoch - 91ms/step\n",
      "Epoch 17/20\n",
      "100/100 - 9s - loss: 0.1307 - accuracy: 0.9550 - val_loss: 0.1256 - val_accuracy: 0.9710 - 9s/epoch - 93ms/step\n",
      "Epoch 18/20\n",
      "100/100 - 10s - loss: 0.1367 - accuracy: 0.9555 - val_loss: 0.1216 - val_accuracy: 0.9680 - 10s/epoch - 96ms/step\n",
      "Epoch 19/20\n",
      "100/100 - 9s - loss: 0.1339 - accuracy: 0.9575 - val_loss: 0.1131 - val_accuracy: 0.9700 - 9s/epoch - 92ms/step\n",
      "Epoch 20/20\n",
      "100/100 - 9s - loss: 0.1028 - accuracy: 0.9650 - val_loss: 0.1485 - val_accuracy: 0.9650 - 9s/epoch - 94ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20, # 100\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with freezing layers\n",
    "\n",
    "Epoch 1/20\n",
    "100/100 - 24s - loss: 0.3438 - accuracy: 0.8690 - val_loss: 0.2176 - val_accuracy: 0.9180 - 24s/epoch - 239ms/step\n",
    "Epoch 2/20\n",
    "100/100 - 10s - loss: 0.2201 - accuracy: 0.9145 - val_loss: 0.1175 - val_accuracy: 0.9610 - 10s/epoch - 99ms/step\n",
    "Epoch 3/20\n",
    "100/100 - 9s - loss: 0.2090 - accuracy: 0.9170 - val_loss: 0.1130 - val_accuracy: 0.9640 - 9s/epoch - 94ms/step\n",
    "Epoch 4/20\n",
    "100/100 - 9s - loss: 0.1926 - accuracy: 0.9270 - val_loss: 0.1003 - val_accuracy: 0.9680 - 9s/epoch - 94ms/step\n",
    "Epoch 5/20\n",
    "100/100 - 9s - loss: 0.1868 - accuracy: 0.9320 - val_loss: 0.1282 - val_accuracy: 0.9610 - 9s/epoch - 93ms/step\n",
    "Epoch 6/20\n",
    "100/100 - 9s - loss: 0.1865 - accuracy: 0.9390 - val_loss: 0.1130 - val_accuracy: 0.9650 - 9s/epoch - 95ms/step\n",
    "Epoch 7/20\n",
    "100/100 - 9s - loss: 0.1937 - accuracy: 0.9305 - val_loss: 0.0969 - val_accuracy: 0.9670 - 9s/epoch - 94ms/step\n",
    "Epoch 8/20\n",
    "100/100 - 10s - loss: 0.1541 - accuracy: 0.9435 - val_loss: 0.1230 - val_accuracy: 0.9610 - 10s/epoch - 97ms/step\n",
    "Epoch 9/20\n",
    "100/100 - 10s - loss: 0.1572 - accuracy: 0.9500 - val_loss: 0.0922 - val_accuracy: 0.9700 - 10s/epoch - 98ms/step\n",
    "Epoch 10/20\n",
    "100/100 - 10s - loss: 0.1650 - accuracy: 0.9465 - val_loss: 0.1333 - val_accuracy: 0.9620 - 10s/epoch - 99ms/step\n",
    "Epoch 11/20\n",
    "100/100 - 10s - loss: 0.1358 - accuracy: 0.9495 - val_loss: 0.1235 - val_accuracy: 0.9660 - 10s/epoch - 96ms/step\n",
    "Epoch 12/20\n",
    "100/100 - 10s - loss: 0.1737 - accuracy: 0.9450 - val_loss: 0.1340 - val_accuracy: 0.9520 - 10s/epoch - 95ms/step\n",
    "Epoch 13/20\n",
    "100/100 - 9s - loss: 0.1276 - accuracy: 0.9515 - val_loss: 0.1083 - val_accuracy: 0.9690 - 9s/epoch - 94ms/step\n",
    "Epoch 14/20\n",
    "100/100 - 10s - loss: 0.1498 - accuracy: 0.9430 - val_loss: 0.1150 - val_accuracy: 0.9640 - 10s/epoch - 96ms/step\n",
    "Epoch 15/20\n",
    "100/100 - 10s - loss: 0.1516 - accuracy: 0.9525 - val_loss: 0.1084 - val_accuracy: 0.9690 - 10s/epoch - 96ms/step\n",
    "Epoch 16/20\n",
    "100/100 - 10s - loss: 0.1572 - accuracy: 0.9470 - val_loss: 0.1588 - val_accuracy: 0.9540 - 10s/epoch - 98ms/step\n",
    "Epoch 17/20\n",
    "100/100 - 10s - loss: 0.1427 - accuracy: 0.9490 - val_loss: 0.1170 - val_accuracy: 0.9700 - 10s/epoch - 98ms/step\n",
    "Epoch 18/20\n",
    "100/100 - 10s - loss: 0.1292 - accuracy: 0.9580 - val_loss: 0.1466 - val_accuracy: 0.9620 - 10s/epoch - 97ms/step\n",
    "Epoch 19/20\n",
    "100/100 - 9s - loss: 0.1071 - accuracy: 0.9555 - val_loss: 0.1243 - val_accuracy: 0.9670 - 9s/epoch - 95ms/step\n",
    "Epoch 20/20\n",
    "100/100 - 9s - loss: 0.1301 - accuracy: 0.9550 - val_loss: 0.1319 - val_accuracy: 0.9630 - 9s/epoch - 94ms/step\n",
    "\n",
    "\n",
    "without freezing layers\n",
    "\n",
    "Epoch 1/20\n",
    "100/100 - 32s - loss: 0.3697 - accuracy: 0.8400 - val_loss: 0.3595 - val_accuracy: 0.9140 - 32s/epoch - 315ms/step\n",
    "Epoch 2/20\n",
    "100/100 - 10s - loss: 0.2227 - accuracy: 0.9080 - val_loss: 0.2001 - val_accuracy: 0.9480 - 10s/epoch - 99ms/step\n",
    "Epoch 3/20\n",
    "100/100 - 10s - loss: 0.1765 - accuracy: 0.9345 - val_loss: 0.2188 - val_accuracy: 0.9580 - 10s/epoch - 100ms/step\n",
    "Epoch 4/20\n",
    "100/100 - 10s - loss: 0.1552 - accuracy: 0.9380 - val_loss: 0.7529 - val_accuracy: 0.9250 - 10s/epoch - 99ms/step\n",
    "Epoch 5/20\n",
    "100/100 - 10s - loss: 0.1342 - accuracy: 0.9515 - val_loss: 0.3002 - val_accuracy: 0.9640 - 10s/epoch - 101ms/step\n",
    "Epoch 6/20\n",
    "100/100 - 10s - loss: 0.1205 - accuracy: 0.9610 - val_loss: 0.2677 - val_accuracy: 0.9590 - 10s/epoch - 100ms/step\n",
    "Epoch 7/20\n",
    "100/100 - 10s - loss: 0.1413 - accuracy: 0.9605 - val_loss: 0.7452 - val_accuracy: 0.9580 - 10s/epoch - 101ms/step\n",
    "Epoch 8/20\n",
    "100/100 - 10s - loss: 0.0946 - accuracy: 0.9690 - val_loss: 0.3574 - val_accuracy: 0.9550 - 10s/epoch - 99ms/step\n",
    "Epoch 9/20\n",
    "100/100 - 10s - loss: 0.1359 - accuracy: 0.9625 - val_loss: 0.6323 - val_accuracy: 0.9520 - 10s/epoch - 100ms/step\n",
    "Epoch 10/20\n",
    "100/100 - 10s - loss: 0.1011 - accuracy: 0.9725 - val_loss: 0.7085 - val_accuracy: 0.9610 - 10s/epoch - 100ms/step\n",
    "Epoch 11/20\n",
    "100/100 - 10s - loss: 0.0875 - accuracy: 0.9700 - val_loss: 0.3422 - val_accuracy: 0.9660 - 10s/epoch - 101ms/step\n",
    "Epoch 12/20\n",
    "100/100 - 10s - loss: 0.0871 - accuracy: 0.9725 - val_loss: 0.3484 - val_accuracy: 0.9540 - 10s/epoch - 100ms/step\n",
    "Epoch 13/20\n",
    "100/100 - 10s - loss: 0.0971 - accuracy: 0.9745 - val_loss: 1.1989 - val_accuracy: 0.9030 - 10s/epoch - 99ms/step\n",
    "Epoch 14/20\n",
    "100/100 - 10s - loss: 0.0680 - accuracy: 0.9820 - val_loss: 0.2448 - val_accuracy: 0.9580 - 10s/epoch - 99ms/step\n",
    "Epoch 15/20\n",
    "100/100 - 10s - loss: 0.0799 - accuracy: 0.9735 - val_loss: 0.3434 - val_accuracy: 0.9670 - 10s/epoch - 97ms/step\n",
    "Epoch 16/20\n",
    "100/100 - 10s - loss: 0.0613 - accuracy: 0.9815 - val_loss: 13.4375 - val_accuracy: 0.9570 - 10s/epoch - 95ms/step\n",
    "Epoch 17/20\n",
    "100/100 - 10s - loss: 0.0754 - accuracy: 0.9785 - val_loss: 5.5575 - val_accuracy: 0.9570 - 10s/epoch - 95ms/step\n",
    "Epoch 18/20\n",
    "100/100 - 9s - loss: 0.0520 - accuracy: 0.9805 - val_loss: 0.5496 - val_accuracy: 0.9730 - 9s/epoch - 95ms/step\n",
    "Epoch 19/20\n",
    "100/100 - 10s - loss: 0.0935 - accuracy: 0.9815 - val_loss: 0.7395 - val_accuracy: 0.9600 - 10s/epoch - 96ms/step\n",
    "Epoch 20/20\n",
    "100/100 - 10s - loss: 0.0725 - accuracy: 0.9800 - val_loss: 0.9159 - val_accuracy: 0.9600 - 10s/epoch - 97ms/step\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwcB2bPj7lIx"
   },
   "source": [
    "## Evaluate the results\n",
    "\n",
    "You will use the same code to plot the results. As you can see, the validation accuracy is also trending upwards as your training accuracy improves. This is a good sign that your model is no longer overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGxCAYAAABBZ+3pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4/klEQVR4nO3dd1xV9f8H8NcFmYI4GSoCairmSjQFcxeONEwtRw5y5CxJy5F7lHuUKX7dmqZWjiwnuQ33SlNxoZiCigNUZN37+f3x+d2Ll3kv3AW8no/HfXDvuWe8zz2Xe9/3MxVCCAEiIiIiC2Zl7gCIiIiIcsKEhYiIiCweExYiIiKyeExYiIiIyOIxYSEiIiKLx4SFiIiILB4TFiIiIrJ4TFiIiIjI4jFhISIiIovHhIUsikKh0Ol28ODBPB1n0qRJUCgUudr24MGDBonB0gUHB8Pb29sijuvt7Y3g4OAct83LtQkPD8ekSZPw7NmzDM81a9YMzZo103ufRGQ4RcwdANHrjh07pvV46tSpOHDgAPbv36+1vHr16nk6Tr9+/dC6detcbVu3bl0cO3YszzGQ7rZu3YpixYoZ9Rjh4eGYPHkygoODUbx4ca3nFi9ebNRjE1HOmLCQRWnYsKHW4zJlysDKyirD8vQSEhLg6Oio83HKly+P8uXL5yrGYsWK5RgPGdZbb71l1uMzOdVNSkoKFAoFihThVwsZHquEKN9p1qwZatSogcOHDyMgIACOjo7o06cPAGDTpk0IDAyEh4cHHBwc4Ovri9GjR+Ply5da+8isSsjb2xvt2rXD7t27UbduXTg4OKBatWpYuXKl1nqZVTsEBwfDyckJN27cQNu2beHk5ARPT0+MGDECSUlJWtv/999/6Ny5M5ydnVG8eHF88sknOHXqFBQKBVavXp3tuT969AiDBw9G9erV4eTkBFdXV7Ro0QJHjhzRWu/27dtQKBSYM2cO5s2bBx8fHzg5OcHf3x/Hjx/PsN/Vq1ejatWqsLOzg6+vL9auXZttHGodOnSAl5cXVCpVhucaNGiAunXrah4vWrQITZo0gaurK4oWLYqaNWti1qxZSElJyfE4mVUJXb16Fa1bt4ajoyNKly6NgQMH4vnz5xm2DQsLQ1BQEMqXLw97e3tUrlwZAwYMQGxsrGadSZMm4euvvwYA+Pj4ZKh6zKxK6MmTJxg8eDDKlSsHW1tbVKxYEWPHjs1wvRUKBYYOHYqffvoJvr6+cHR0RO3atfHnn3/meN6JiYkYMWIE6tSpAxcXF5QsWRL+/v74/fffM6yrUqmwcOFC1KlTBw4ODihevDgaNmyI7du3a633888/w9/fH05OTnByckKdOnWwYsWKbF/rzF4D9f/BTz/9hBEjRqBcuXKws7PDjRs3dH6fAkBSUhKmTJkCX19f2Nvbo1SpUmjevDnCw8MBAC1btkS1atWQfp5eIQQqV66M999/P8fXkQoGpsGUL0VHR6NHjx4YOXIkvvvuO1hZydz7+vXraNu2LUJCQlC0aFFcvXoVM2fOxMmTJzNUK2XmwoULGDFiBEaPHg03NzcsX74cffv2ReXKldGkSZNst01JScEHH3yAvn37YsSIETh8+DCmTp0KFxcXTJgwAQDw8uVLNG/eHE+ePMHMmTNRuXJl7N69G126dNHpvJ88eQIAmDhxItzd3fHixQts3boVzZo1w759+zJ8qS5atAjVqlXDggULAADjx49H27ZtERkZCRcXFwAyWfn0008RFBSEuXPnIi4uDpMmTUJSUpLmdc1Knz59EBQUhP379+Pdd9/VLL969SpOnjyJH374QbPs5s2b6N69O3x8fGBra4sLFy7g22+/xdWrVzMkhTl58OABmjZtChsbGyxevBhubm5Yv349hg4dmmHdmzdvwt/fH/369YOLiwtu376NefPm4Z133sHFixdhY2ODfv364cmTJ1i4cCG2bNkCDw8PAFmXrCQmJqJ58+a4efMmJk+ejFq1auHIkSOYPn06zp8/jx07dmitv2PHDpw6dQpTpkyBk5MTZs2ahQ8//BARERGoWLFilueZlJSEJ0+e4KuvvkK5cuWQnJyMv/76Cx07dsSqVavQq1cvzbrBwcFYt24d+vbtiylTpsDW1hZnz57F7du3NetMmDABU6dORceOHTFixAi4uLjg0qVLuHPnjj4vv5YxY8bA398fS5YsgZWVFVxdXfHo0SMAOb9PU1NT0aZNGxw5cgQhISFo0aIFUlNTcfz4cURFRSEgIADDhg1DUFAQ9u3bp/Ue27VrF27evKn1HqMCThBZsN69e4uiRYtqLWvatKkAIPbt25fttiqVSqSkpIhDhw4JAOLChQua5yZOnCjSv/29vLyEvb29uHPnjmbZq1evRMmSJcWAAQM0yw4cOCAAiAMHDmjFCUD88ssvWvts27atqFq1qubxokWLBACxa9curfUGDBggAIhVq1Zle07ppaamipSUFNGyZUvx4YcfapZHRkYKAKJmzZoiNTVVs/zkyZMCgNiwYYMQQgilUinKli0r6tatK1QqlWa927dvCxsbG+Hl5ZXt8VNSUoSbm5vo3r271vKRI0cKW1tbERsbm+l2SqVSpKSkiLVr1wpra2vx5MkTzXO9e/fOcFwvLy/Ru3dvzeNRo0YJhUIhzp8/r7Xee++9l+HavE79nrhz544AIH7//XfNc7NnzxYARGRkZIbtmjZtKpo2bap5vGTJkkyv98yZMwUAsXfvXs0yAMLNzU3Ex8drlsXExAgrKysxffr0TOPMivp69+3bV7z11lua5YcPHxYAxNixY7Pc9tatW8La2lp88skn2R4j/Wutlv41UP8fNGnSROe4079P165dKwCIZcuWZbmtUqkUFStWFEFBQVrL27RpIypVqqT1vqWCjVVClC+VKFECLVq0yLD81q1b6N69O9zd3WFtbQ0bGxs0bdoUAHDlypUc91unTh1UqFBB89je3h5VqlTR6ReoQqFA+/bttZbVqlVLa9tDhw7B2dk5Q4Pfbt265bh/tSVLlqBu3bqwt7dHkSJFYGNjg3379mV6fu+//z6sra214gGgiSkiIgL3799H9+7dtarIvLy8EBAQkGMsRYoUQY8ePbBlyxbExcUBAJRKJX766ScEBQWhVKlSmnXPnTuHDz74AKVKldJcm169ekGpVOLatWs6nz8AHDhwAG+++SZq166ttbx79+4Z1n348CEGDhwIT09Pzevl5eUFQLf3RGb279+PokWLonPnzlrL1VUp+/bt01revHlzODs7ax67ubnB1dVVp/fVr7/+ikaNGsHJyUkT/4oVK7Ri37VrFwBgyJAhWe4nLCwMSqUy23Vyo1OnTpku1+V9umvXLtjb22uqdDNjZWWFoUOH4s8//0RUVBQAWWq2e/duDB48ONe9/Sj/YcJC+ZK6yP51L168QOPGjXHixAlMmzYNBw8exKlTp7BlyxYAwKtXr3Lc7+tfsGp2dnY6bevo6Ah7e/sM2yYmJmoeP378GG5ubhm2zWxZZubNm4dBgwahQYMG2Lx5M44fP45Tp06hdevWmcaY/nzs7OwApL0Wjx8/BgC4u7tn2DazZZnp06cPEhMTsXHjRgDAnj17EB0djU8//VSzTlRUFBo3box79+7h+++/x5EjR3Dq1CksWrRIKx5dPX78WKeYVSoVAgMDsWXLFowcORL79u3DyZMnNe149D1u+uOn/7J0dXVFkSJFNK+rWm7fV1u2bMHHH3+McuXKYd26dTh27BhOnTqlec3VHj16BGtr62yvmbqaJreNzbOS2f+iru/TR48eoWzZsjpVPTo4OGDJkiUAZFWng4NDtokOFTxsw0L5Uma/qvbv34/79+/j4MGDmlIVAJmOq2EupUqVwsmTJzMsj4mJ0Wn7devWoVmzZggNDdVanlljU13jyer4usZUvXp1vP3221i1ahUGDBiAVatWoWzZsggMDNSss23bNrx8+RJbtmzRlG4AwPnz53Mdty4xX7p0CRcuXMDq1avRu3dvzfIbN27k6rivH//EiRMQQmi9Fx8+fIjU1FSULl06T/tXW7duHXx8fLBp0yat46Rv2FumTBkolUrExMRkmkCo1wFko29PT88sj2lvb59h/wAQGxub6Xll9r+o6/u0TJkyOHr0KFQqVbZJi4uLC3r37o3ly5fjq6++wqpVq9C9e/cM3c+pYGMJCxUY6g9OdSmC2v/+9z9zhJOppk2b4vnz55oifDV16UROFApFhvP7559/Moxfo6uqVavCw8MDGzZs0OqFcefOHU0vDV18+umnOHHiBI4ePYo//vgDvXv31qqKyuzaCCGwbNmyXMXdvHlz/Pvvv7hw4YLW8p9//lnrsT7vifSlT9lp2bIlXrx4gW3btmktV/euatmyZY770IVCoYCtra1WUhATE5Ohl1CbNm0AIEOC8LrAwEBYW1tnuw4gewn9888/WsuuXbuGiIgIveLW5X3apk0bJCYm5tg7DgC++OILxMbGonPnznj27FmmDaypYGMJCxUYAQEBKFGiBAYOHIiJEyfCxsYG69evz/ClZk69e/fG/Pnz0aNHD0ybNg2VK1fGrl27sGfPHgDIsWi8Xbt2mDp1KiZOnIimTZsiIiICU6ZMgY+PD1JTU/WOx8rKClOnTkW/fv3w4Ycfon///nj27BkmTZqkc5UQINvgDB8+HN26dUNSUlKGbrHvvfcebG1t0a1bN4wcORKJiYkIDQ3F06dP9Y4ZAEJCQrBy5Uq8//77mDZtmqaX0NWrV7XWq1atGipVqoTRo0dDCIGSJUvijz/+QFhYWIZ91qxZEwDw/fffo3fv3rCxsUHVqlW12p6o9erVC4sWLULv3r1x+/Zt1KxZE0ePHsV3332Htm3bavVmyYt27dphy5YtGDx4MDp37oy7d+9i6tSp8PDwwPXr1zXrNW7cGD179sS0adPw4MEDtGvXDnZ2djh37hwcHR3x+eefw9vbG9988w2mTp2KV69eoVu3bnBxccHly5cRGxuLyZMnAwB69uyJHj16YPDgwejUqRPu3LmDWbNmaUpodI1bl/dpt27dsGrVKgwcOBARERFo3rw5VCoVTpw4AV9fX3Tt2lWzbpUqVdC6dWvs2rUL77zzTob2S1QImLfNL1H2suol9Oabb2a6fnh4uPD39xeOjo6iTJkyol+/fuLs2bMZeuBk1Uvo/fffz7DPrHpHpO8llD7OrI4TFRUlOnbsKJycnISzs7Po1KmT2LlzZ4ZeK5lJSkoSX331lShXrpywt7cXdevWFdu2bcvQs0bdS2j27NkZ9gFATJw4UWvZ8uXLxRtvvCFsbW1FlSpVxMqVKzPtrZOd7t27CwCiUaNGmT7/xx9/iNq1awt7e3tRrlw58fXXX4tdu3Zl+lrm1EtICCEuX74s3nvvPWFvby9Kliwp+vbtK37//fcM+1Ov5+zsLEqUKCE++ugjERUVlenrMGbMGFG2bFlhZWWltZ/07wEhhHj8+LEYOHCg8PDwEEWKFBFeXl5izJgxIjExUWs9AGLIkCEZXo+seuOkN2PGDOHt7S3s7OyEr6+vWLZsWabvK6VSKebPny9q1KghbG1thYuLi/D39xd//PGH1npr164V9evXF/b29sLJyUm89dZbWv8bKpVKzJo1S1SsWFHY29uLevXqif3792f5f/Drr79miFnX96kQsifehAkTNO+/UqVKiRYtWojw8PAM+129erUAIDZu3Jjj60YFj0KIdKPxEJHJfffddxg3bhyioqIM3iiSqKDo1KkTjh8/jtu3b8PGxsbc4ZCJsUqIyMR+/PFHALK6IiUlBfv378cPP/yAHj16MFkhSicpKQlnz57FyZMnsXXrVsybN4/JSiHFhIXIxBwdHTF//nzcvn0bSUlJqFChAkaNGoVx48aZOzQiixMdHY2AgAAUK1YMAwYMwOeff27ukMhMWCVEREREFo/dmomIiMjiMWEhIiIii8eEhYiIiCxegWl0q1KpcP/+fTg7O3MyLCIionxCCIHnz5/nOK9UgUlY7t+/n+38GERERGS57t69m+3QDgUmYVEPn3337l0UK1bMzNEQERGRLuLj4+Hp6ZnpNBivKzAJi7oaqFixYkxYiIiI8pmcmnOw0S0RERFZPCYsREREZPGYsBAREZHFY8JCREREFo8JCxEREVk8JixERERk8ZiwEBERkcVjwkJEREQWjwkLERERWTwmLERERGTxmLAQERGRxWPCQkRERBaPCQsRkR7+/ReYOxeIjzd3JESFCxMWIiIdXb8ONGkCfPUV0Lw58PChuSMiKjyYsBAR6eDpU6BdO+DJE/n47FmgcWPgzh3zxkVUWDBhISKT270buHjR3FHoLiUF6NwZuHYN8PQEDh0CKlSQjxs1Ai5fNneElFdCAPv2Abt2yetNlocJCxGZ1KlTQJs2QIMGwJEj5o4mZ0IAQ4cC+/cDTk7An3/KaqG//waqVwfu3ZMlLSdOmDtSyg0hgLAw4O23gXffBdq2lcnoN98AN2+aOzp6HRMWIjKpNWvk31evgPffB06fNm88Ofn+e2DpUkChADZsAGrVksvLlwcOH5aJ15MnQMuW8ouP8o/jx+V1CwyU70MnJ8DVFYiJAaZPBypXlknMpk1AUpK5oyUmLERkMsnJwMaN8n7FisDz50CrVsClS+aNKyt//gkMHy7vz50r27C8rlQp4K+/gPfeA16+lAnYr7+aPk7Sz6VLQIcOgL8/cOAAYGsLhIQAt24Bd+8Cv/0m35cKhawm6tpVJqgjRgBXr5o7+szdvy8TsAJdnSUKiLi4OAFAxMXFmTsUIsrC778LAQjh7i7E06dCNGiQ9vjaNXNHp+3CBSGcnGR8n30mhEqV9bqJiUJ89JFcV6EQYskS08VJurt5U4gePeQ1AoSwshKib18h7tzJfP3ISCHGjxeiXDm5vvrWuLEQa9cKkZBg0vC1PH0qxNatQgwdKkS1ammx1akjxLlz5osrN3T9/mbCQkQmo/5S//JL+fjxYyFq1ZLLKlTI+ovD1KKjZTyAEC1aCJGcnPM2qalCDBiQ9sXx7bfZJzlkOvfvCzF4sBA2NmnX56OPhLh6VbftU1KE2L5diPbtZZKj3kfx4jJhuHDBuPELIcSrV0Ls2yfEmDFCvP22dhzqRNnRUd4vUkQmWomJxo/LEJiwEJFFefpUCDs7+YF69mza8pgYIapUkcvfeEMmC+aUkJBW8lOlihBPnui+rUolxLhxaV8iX34phFJpvFgpe0+eCDFqlBAODmnXpFUrIU6fzv0+//tPiKlThfDy0k4YGjQQYvlyIZ4/N0zsqalCnDolxPTpQrz7rhD29trHA4SoWlUmYlu2yHONiRGiU6e05998U4iTJw0TjzExYSEii7J8ufwQrV49Y8lDVFTaF0DNmrLkxRxUKiG6dJFxlCiR+2qq+fPTvjR69dKthIYM58ULWcLl4pJ2Hfz9hTh40HDHUCqF2LNHiM6dZYmG+jhOTrIKUd+kSKWSJT6LFgnx4Yey9CZ9guLhIau0Vq8W4u7drPf1yy9ClCmTVu01cqQsobFUTFiIyKI0bSo/QKdPz/z569dlWxZAiPr1hTDHv/LEiWlF6gcO5G1fa9cKYW0t99e+vXnbOxQWiYlCLFwohJtb2pd8zZqyOseY1XMxMULMnClE5craCcZbbwmxeLEQz55lvt39+0L89JMQvXsLUb58xgSlWDEhgoKE+OEHIS5f1u8cHj0Sols37dKYv/82xNkaHhMWohwkJ7ONgancuZP2wRkVlfV6ly4JUaqUXK9JEyFevjRdjOvXp8W4fLlh9rl9e1pRfuPGWX9xUd6kpspSB2/vtGtYsaIQ69aZtkpOpZKJbvfuQtjapsXi6ChEcLAQhw4JsW2bEJ9/LoSvb8YExdZWiObNhZg2TYjjx2Xbmbzati3th4BCIURIiGn/r3TBhIUKPZVKtof4+2/5wTVlivzQaNpUCE9P+c/r4yM/6FJTzR1twfbdd/IDs1mznNc9fVr+sgSEaN3aNA0Hw8PT2td8/bVh9334cNr51K4tf42TYahUsv1G9era1SahoeavhouNlVWDr8eW/qZQCOHnJ9vZ7N1rvETiyRNZiqM+bqVKeS9BNCQmLFQovHghxMWLsrvsggVCfPGFEO3ayQ+J1xva5XTz9RVi82aWuBiDSpX2a3LFCt22OXIk7fp17GiYX5pZiYwUwtVVHisoyDjJ67lzadUUlSsLceuW4Y9R2Pz1l+wto/4fLlFCVstYWumBSiV/NAUHy8S1ShUhBg0S4rffTN9Wa+dO7aqnwYOFiI83bQyZ0fX7WyGEEKYf/cXw4uPj4eLigri4OBQrVszc4ZCBKJVy6PNbt+QtMjLt/q1bOc+Wa2Ul536pWFHefHzS7pcrJ0cunT5dTmwHAPXrA999J0e3JMM4exbw8wPs7eUIoi4uum0XFiYHaktOBnr2BFavltfTkOLj5VxAly4BderIqQKcnAx7DLUbN+QAc7dvAx4ewN69QI0axjlWQXbypBw2f98++djREfjySzmDdvHiZg0tX4iLA0aOlKM3A4CXF7BsmXxvmouu399MWMjsnj7VTkRev3/nTs4jN5YsqZ2IvH6/QgXAxib77ePigDlzgPnz5WilANCihUxcGjQwzDkWZl9+CSxYAHz8sRziXB+//w506iQT10GDgEWL5OijhpCaCnzwgZzszsNDfhGWL2+YfWfl/v20kX2LFwd27pSjrVLWkpKAY8fkiMJ//ZU2Z5ONDTBwIDB2LODmZt4Y86N9+4B+/WQCDcj7c+bo/oPCkJiwkMVITpaJR1ZJybNn2W9vYyOTkMySEh8fw/2qevBAJilLlsiYATl897RpwJtvGuYYhU1qqkwCHjwAtm8H2rfXfx8//wz06CELsUeOBGbMMEzSEhIi5wlycJBzAtWrl/d96uLpU1lyFB4uSwc2bwZatzbNsfMDlQo4f14mJ/v2yVKvV6/SnreykiVukyYB3t5mCrKAePECGDMG+PFH+bhcOeB//5NTTJgSExYyGSFk1Uz6RER9/7//5IdQdtzdtRMSdTLi4yP/iaytTXMugEyuJk+Wk/SpVPLLsUcPuczHx3RxFAS7d8uZmUuVAqKjcy7tysrSpcCAAfL+tGnyV3VehIYCgwfL+7/+CnTunLf96evlS3nM3buBIkWAtWuBbt1MG4OlEEJWl+3bJ2/798vJJF/n5iYnKXz3XVl1YeySsMLm8GGgb195HQCZEC5YIEuvTUHn728jt6UxGTa6Nb1Nm+S8FerhoLO7OToKUaOGHI9i2DAhvv9eiD/+kN1YX7ww95lk7vJl7VEjbWyEGDLEvCOxRkfL7reffipHv7x+3Xyx6OKTT+RrN2RI3vc1d27atViwIPf72bs3bXyUb7/Ne1y5lZSUNk6GQiEHDCssXn8fq6dAeP3m7Cw/KxYskJ8RbAxvfC9fCjF8eNo8S25usgeWKbCXEBlNSooQI0Zk7J5XoYLsMvzpp3Lo6vXrZXfRmJj8/YFz6pQQ772nnXyNGSOHmje2uDg5lsewYTLhS//B3qmT8WPIrefP05LZ48cNs89Jk9LOXdceR6+7fDlt9NOePc3/vlQq5Vw06nOaPNn8MRlDXJz8gZLV+9jGRn52TJ0qPzOM2SuMshcerj2ZYpcuQjx8aNxjMmEho3jwQI6loX4zjxwphy/PL5Ns5cX+/WlzzABy6Ozp0w3bjTIxUQ4fPn68HEpcXRLwemL41luyO6L68ZUrhju+Ia1ZI2N84w3DfQmrVGnJskIhxMaNum/76JEcTAwQolEjy3nPqlTaidjnn+f/+Yd0eR/XrSvHvNm923JLWQurV6+EGD067bqVLi3/11TJxskkmbCQwZ04kdaH38lJjiNQ2KhUcsyX138lurvL4vykJP33p1TKiQBnz5aTsmVWvVa5spwF+Jdf5JeuWlCQfD442GCnZ1DqUqnJkw27X5UqbVbkIkVkCVROEhPlSLOAHCzQ2L8Yc2PhwrRr/tFHctj2/ESlEmLHDjnYX3bv419/lYOqkeU7dUpObaC+hh+WOiSibxp+oBsmLGRQy5enDTVdtaosWi/MUlPlHCA+Pmn/zD4+cv6Y7AYeU6mEuHFDiCVL5JeSehj612+urrJtw4oVQty+nfW+jh9P+9K+c8fw55gX9+7JSdcAIW7eNPz+lcq09jF2dnIQsayoVGmjfBYrJsS//xo+HkNZvz5tIj0HBzkCqrkmgtTH4cNCvPOO9vvYzU0OUZ/T+5gsW1KSEBPe/VsUQbIAhPh18D6DH4MJCxlEYqKceVT9IRQUZJ5J6SxVUpIsXVHP1QHI0pdt29KqQWJihPj5ZyH69s04Jb26tOr99+Uw3v/8o1/1SYsWadUIlmTOHBlXQIDxjpGSIkSHDvI4RYvKuvfMTJ8u17G2ltUPli48XL5u6veHi4ucW+b5c3NHltG5c0K0aZMWq729EF99JUefLohtcQql//8HOo9a4pvGh41yCCYslGd376YNfa1QyB4V+b1u3VhevBBixgztKeH9/LSLU19vYNikiawqOXo0b3OehIWl/Rp/8MBw55NXtWvLuEJDjXucxEQhAgPTvtjPntV+fvPmtNc9P/XCUalkI9VatbRL3n74wTLa3ly7JhtjqmOztpbVPf/9Z+7IyKCmTUu7yFOmGO0wTFgoTw4eTJtfpUSJ/PHL1BI8fSrEN99krMOvU0c2Ft21y7ANDFUqIerXl8f45hvD7Tcv/vknLTEzRVuFly/TqiNKl06rrjx9Om0+IksrgdKVUilL5ypVSnsveXmZb8LOu3eF6N9fuxFtt26W372ecuH1luBG7v/PhIVyRaWSVRPqD6TatY3TBqGgi46WY0hs2mT8Bp5btqSVMFjC23/kSBlPhw6mO+azZ7JECxCibFk5eWLZsvJx69b5v5tscrJs9+ThkfYdYsoJOx89kmN0qGe0BmQ15vnzxj82mZhKJcSECWkXesYMox+SCQvp7cUL2UhO/T795BPLm/mUMlIq02ZDNsFnS46xlCsnYzF1L7LYWCHefFO7ZOvNN2UyU1C8fCnErFmy1FN9jvXry6pBY4iPlz+0nZ3TjtekiazKpAJIpRJi7Ni0iz17tkkOy4SF9HLjRlp9eZEisq6cjebyD/WYJ66uQiQkmC+OfftkHMWLy7EcTO3+fdl9FhCiTBkhbt0yfQym8OyZEOPGycbG6u+WFi0MN0Dfq1dCzJsnq9jU+3/rLVmlyc+FAkqlkoOvqC/4vHkmOzQTFtLZzp1pjUXd3IQ4dMjcEZG+kpPTeiCZs3FpcLCMoX9/88UQFSWrpf75x3wxmEpMjBBffJE25IC6Ku7SpdztLyVFDmHg6Zm2vypVZNUmG9wXYCqVHMVPfdG//96kh2fCQjlSKmXDb/XcEQ0bspV/fvbjj2mNMvPS8yi3Xr5Mqzo4bJzej5SF27fllBjqsW8UCjn1gK4lTEqlHJiwatW076zy5YVYtiz/t/+hHKhUsoGS+sL/+KPJQ9D1+9vK0LMuUv4QFwd07AhMmCDfpQMHAgcPypmRKX/q0wdwdZWzTW/caPrjb98OPH8OeHsDjRqZ/viFmZcXsHIlcOkS0KmT/J/+6SegalVg6FAgJibz7YSQM0bXrw98/DEQESFn1p47F7h+HejXT84mTQWUEMCXXwLz5snHoaHAkCHmjSkbTFgKocuXgbffBn7/HbCzA1askO9TOztzR0Z54eAgP3sAYPp0QKUy7fHXrZN/P/kEsOIni1n4+gK//QacOgW89x6QkgIsWgRUqgR88w3w7FnauuHhQLNmQJs2wNmzgLMzMGkScOsWMHw4YG9vppMg0xAC+OIL4Pvv5eP//U/+crVgCiGEMHcQhhAfHw8XFxfExcWhWLFi5g7HYv32GxAcDLx8CXh6Aps3y19XVDDExclf23FxwNatQIcOpjnuw4dA2bKAUglcuQJUq2aa41L2DhwAxowBTpyQj4sXl0nt6dPAH3/IZXZ28kf1mDFA6dJmC5VMSaWSRW+hoYBCASxfLotozUTX7+9c/Q5avHgxfHx8YG9vDz8/Pxw5ciTb9RctWgRfX184ODigatWqWLt2bYZ1nj17hiFDhsDDwwP29vbw9fXFzp07cxMeZSI1FRg1CvjoI5mstGgBnDnDZKWgcXFJK9H97jv5I8oUNm2SyUq9ekxWLEnz5sCxY7I0tUYNWcIycaJMVqytZZXP9euyCojJSiGhUgGDBqUlK6tWmTVZ0Yu+jWM2btwobGxsxLJly8Tly5fFsGHDRNGiRcWdLGZfW7x4sXB2dhYbN24UN2/eFBs2bBBOTk5i+2tTrCYlJYl69eqJtm3biqNHj4rbt2+LI0eOiPN6jErERrdZe/RIiHffTWtT9dVXbEhXkD14kDbCa3aTAhqSerRdE3cuID2oJ+ysU0eIrl2FiIgwd0RkckqlEP36yX9WKys5W6sFMFovobffflsMHDhQa1m1atXE6NGjM13f399ffPXVV1rLhg0bJho1aqR5HBoaKipWrCiS89C1gQlL5k6fFqJChbQJ4jZtMndEZAqff542NoexXb2aNp+MJc1nRESvSU1NG3fAykpODW4hjNJLKDk5GWfOnEFgYKDW8sDAQISHh2e6TVJSEuzTtd5ycHDAyZMnkZKSAgDYvn07/P39MWTIELi5uaFGjRr47rvvoFQqs4wlKSkJ8fHxWjfS9u+/wDvvAFFRQOXKwPHjsicAFXxffSV7d+zfn9Z+wVjUjW1btZK9lIjIwiiVwKefAqtXy7rA9euB7t3NHZXe9EpYYmNjoVQq4ebmprXczc0NMVn0m2vVqhWWL1+OM2fOQAiB06dPY+XKlUhJSUFsbCwA4NatW/jtt9+gVCqxc+dOjBs3DnPnzsW3336bZSzTp0+Hi4uL5ubp6anPqRQKc+cCiYlAkyay10CNGuaOiEylQgWgRw95f/p04x1HpUpLWNTHIyILkpoK9O4t+7lbWwMbNgBdu5o7qlzJVaNbhUKh9VgIkWGZ2vjx49GmTRs0bNgQNjY2CAoKQnBwMADA2toaAKBSqeDq6oqlS5fCz88PXbt2xdixYxEaGpplDGPGjEFcXJzmdvfu3dycSoH1+DHw88/y/syZsncAFS6jRsk2db//LkvbjCE8HLh9W3aJDQoyzjGIKJdSU4GePWWJSpEisnX8Rx+ZO6pc0ythKV26NKytrTOUpjx8+DBDqYuag4MDVq5ciYSEBNy+fRtRUVHw9vaGs7MzSv9/s3QPDw9UqVJFk8AAgK+vL2JiYpCcnJzpfu3s7FCsWDGtG6VZsQJISgL8/IAGDcwdDZlDtWpycEAAmDHDOMf46Sf5t1MnwNHROMcgolxISZGDIm3cCNjYAL/+Kv9R8zG9EhZbW1v4+fkhLCxMa3lYWBgCAgKy3dbGxgbly5eHtbU1Nm7ciHbt2sHq/0eXatSoEW7cuAHVayNdXbt2DR4eHrC1tdUnRIKsrly8WN4fOlT+yqbCacwY+XfDBiAy0rD7TkoCfvlF3md1EJEFSUkBunWT/6A2NnLALVMNymRM+rbmVXdrXrFihbh8+bIICQkRRYsWFbdv3xZCCDF69GjRs2dPzfoRERHip59+EteuXRMnTpwQXbp0ESVLlhSRkZGadaKiooSTk5MYOnSoiIiIEH/++adwdXUV06ZN0zku9hJK8/vvsiF4qVLmnbmXLENgoHw/DBpk2P1u3iz3W66c7IBARBYgKUmIDz+U/5y2tkL8+ae5I8qRrt/fes8S0aVLFzx+/BhTpkxBdHQ0atSogZ07d8LLywsAEB0djaioKM36SqUSc+fORUREBGxsbNC8eXOEh4fD29tbs46npyf27t2LL7/8ErVq1UK5cuUwbNgwjBo1Kq/5WKH044/yb79+crh2Kty++QbYu1fONTNhAuDubpj9qquDuneXbfmIyMySkmRX0O3b5RDGW7fKuRcKCA7NX8BcvSrnE7GyAm7elBPRUeEmhJyM8NgxYORI2Qg7r548kYlPSgrwzz9AzZp53ycR5UF8vGyz8uefciKobdvkWAP5gFGH5ifLpW670r49kxWSFApZygLI0bifPs37Pn/5RSYrtWoxWSEyi+Rk4PBhOddCo0Zymu0//5TF6n/8kW+SFX1w4vAC5PlzOS4QIBvbEqm9/75MLC5elLP3jhuXt/2px17p2TPvsRGRDlQqWZz511/Avn0yWUlI0F6nShU563KzZmYJ0dhYJVSALF4sJ76rWlXOmMveQfS6DRtke5PSpeXYKUWL5m4/t24BlSrJ99fdu0C5cgYNk4gAWZd765ZMTv76S069/f+DrWq4ugItW6bd8mmxuq7f3yxhKSCESGtsy67MlJmPPpIlK7duydnkhw3L3X7Wr5d/W7ZkskJkUA8eyPk09u2Tt9u3tZ93cgKaNpX/fO++K4cvL0Qf9kxYCogDB2SpipMT0KuXuaMhS1SkiBz9dsAAYM4cOcO8vsMcCZHWO4jVQUR59Py5rNpRl6JcvKj9vI0N0LChTE5atgTeflsuK6SYsBQQ6tKVXr2AQlojRjro3RuYNAn47z/ZDqVPH/22P3UKuH5dtuv78EOjhEhUcCUny9lI1e1QTpyQw+e/rnbttASlcWP5K5QAMGEpEKKi5HwxgGzDQpQVOztgxAg5m/PMmTKB0WcMFXXpyocfyvmDiEwmJQUYPFhOkla0KFCiRNqteHHtx+lv6ueLFct7FYpKJbsQP30qb8+epd3P6vb6Okql9v58fNISlBYtgDJl8hZfAcaEpQBYskT+D7VoAVSvbu5oyNJ99hnw7bfAtWvAli26z4WWkiKnJQE4FD+ZWHKyHGp+yxb5OCEBePRI//1YWWVMbtI/FiL7ZCQuTn7g5laZMvLDWp2k+Pjkfl+FDBOWfC4xEVi2TN5nV2bShbMz8MUXwOTJwPTpQOfOuv3o3LNHdlJwdQXee8/4cRIBkMnKxx/LYmRbW1mXWa1aziUZ6W9JSTLRePJE3vLK3j7rkpzsSnnKlpWJE+mNCUs+98sv8kvE01MOFkeki88/lw1vz52TiUjr1jlvo64O6tZNNuAlMrqkJFkE+McfeR9qPjFRtyRHodAt+bC3N+CJki74sZPPqRvbDhrELxHSXalSsrfQvHmylCWnhCUuTk5PArB3EJlIYqIs/tuxwzBDzdvbAx4e8kb5Esul8rGTJ2WvDVtbOdEhkT6GD5c9JA8fBv7+O/t1N2+W3x/VqgF165omPirEEhNly+4dOwr0UPOkHyYs+Zi6dKVrVzYsJ/2VKwcEB8v706dnv+7rQ/Fb/DhVUVGy3mrWLDkQF+Uvr14BH3wA7N4tk5U//5QNVKnQ49D8+dTDh7LdSnKyLGmpX9/cEVF+dOOGnMpBpQLOn5dDQKR39y7g5SU7T0RG5oPRvzt2lG0dAFlPGhQE9O8vWwqzsaNlS0iQycq+fYCjI7BzpxzZlQo0ztZcwC1fLpOVt99mskK5V7my7IABADNmZL7O+vUyWWnSJB8kK+fOyWRFoZD/GKmpsj6rdWugYkVg6lTg3j1zR0mZefkSaNdOJitFi8oSFiYr9BomLPlQaioQGirvsysz5dXo0fLvL7/IEpfX5buh+CdNkn+7d5dFj//8I7tEFS8O3LkDTJgAVKggf8X/8UfGUUbJPF68kFOKHzggR3bds0eO8kr0GiYsOVAqgWPHzB2Ftu3b5dDqZcroPugXUVZq15bfFSqVbPbxuvPngcuXZY/Szp3NEp7uTp+W/xxWVjIxAYCaNYEffgDu35eZV+PG8kT/+EMmLV5ewPjxGSeZI9N5/hxo2xY4dEgOErR3L9CokbmjIgvEhCUbCQmyJLlJEyA83NzRpFE3tu3fn0MBkGGMGSP/rl6tXWOibmzbvr0spLBoEyfKvz16AFWqaD/n4CCXHz4sZwkdMQIoXVomMtOmyeqiVq1k9VFysuljL6zi4+WH7JEjctj8sDDA39/cUZGFYsKSDQcH+ZmWmgp06SIHaDO3f/+VpaZWVsDAgeaOhgqKRo1kYp6SIsdmAeT7/uef5X2LH4r/xAnZQNPaWpaYZKdaNTlq3n//AZs2yeHRhZC/7Dt3lq3ZR42SszwWJE+fAvv3yxKn/fvlOZtTXJxMEsPDZTb8119AgwbmjYksmygg4uLiBAARFxdn0P3GxwtRpYoQgBCtWgmhVBp093obNEjG0rGjeeOggmfXLvneKlpUiNhYIfbskY9LlhQiKcnc0eWgVSsZ7Kef5m77GzeEGDNGCHd3uR/1rVkzIX7+WYhXrwwbr7HFxgqxd68Q06cL8dFHQlSsqH1egBBvvSXEhg1CpKSYPr6nT4V4+20ZR4kSQpw+bfoYyGLo+v3Nbs06uHhRJv6vXsnS47FjDbp7ncXFybEzXr6UP5CaNzdPHFQwCQH4+cmONhMnAjdvyiqhQYOAxYvNHV02wsNlEVGRIkBEhKzeya2UFDlY2bJlwK5daaUQJUsCvXrJelhLm2H04UPgzBng7Nm0v3fuZL6uj48sYTp0SNZ5A7Lr14gRwKefyt45xvb0KRAYKNsclSwpS1beesv4xyWLpev3NxMWHa1eLf+frazk/5c5koUffgCGDZOfl5cu5YMBvCjf+fVX2c25RAnZlOPlS5kPWHSzgvfek/+U/fqlzQRqCFFRwMqVwIoVsvpILSBAdpny9Mw4x4ydneGOn5noaO3k5MyZrLtpV64sM9C6deXft96SCQIAPH4ss9Affkir6y5VSnY7HDLEeCNRPnkir9fZs/J4+/ZlPvgPFSpMWIygTx9g1SrAzU3+CjXllBQqFeDrC1y7Jj9nBg0y3bGp8FAqZUJ87Zp8XKmSbMphscnxkSOy8Y2NjQzaGAPFKJWym+2yZbJ3kVKZ9bqZzeCr60y+jo5pL7QQMhFRJyXqBCUmJuMxFQrZyDh9cuLikvO5JSQAa9bINj23bsllDg7yw2748LyVVqX3+LEcsfb8edk4cN8+oFYtw+2f8i0mLEaQkAA0bCiriJo2lT/qTDXh4N69sn1asWLyc8zJyTTHpcJn5Uqgb195f+LEtKFNLFKLFrIV+oABwJIlxj9edLT81XLggCwtUM/wGxeX90asNjZpCcyTJ8CjRxnXsbKSv1zUiUndukCdOrI7cF4olcCWLcDMmTIxUh/ro4+Ar7+Wx8qLR49ksvLPP4Crq0xWatTI2z6pwGDCYiQREUC9enKco2++Ab791miH0qIe5+qLL4DvvzfNMalwSk4G3nxTJsaXLhn2R7ZBHTwo62ZtbWUxUIUK5otFpZJddNUJTPrbs2fZP5dZqY21tbwQ6uTEz0+WSBiznYkQ8nWdNUuONKvWsiUwcqSsztG3uO3hQ7n9pUuyeHr/fstrB0RmxYTFiDZtkhMOArInZZs2Rj0cIiNl0bwQwNWrcu4XImOKjZXjefn4mDuSLAgBNGsmx1UZMiRtcKL8SAj5C+j1JMbRUQ565+BgvrguXJBVRRs2pCVUtWvLxOWjj2SJUE4ePJClYJcvyzr0/ftlo1+i1zBhMbKhQ4FFi2QbtvPnZfs7Yxk5Epg9Wzas37PHeMchyjf27ZNVDHZ2sjtTuXLmjqjgunMHWLBAtuF5+VIu8/KSbVz69s26xCcmRiYrV64AZcvKarT0A/oRgZMfGt3cubKE9skT2avCWINjJiTIiQ4BzhtEBECWSKhHtR0wgMmKsXl5AfPny15T06bJHkR37sguixUqyGkQHj7U3ub+fVkCduWKvD4HDzJZoTxjwpJLdnayC2jx4sDx42kTyBnaxo2yhNjbW063QVTohYUBf/8te+QY6x+PMipZUg5CdeeObOBcubL8xTZ1qkxqBg+Ws2feuyeTlYgIWfR86BDwxhvmjp4KACYseeDjI3sEAvIHyNatht2/EMDChfL+4MGyDR5RoSZE2sSGgwaZdmwBkhwcZMnW1avAb78B9esDiYlyCvmqVWU7l+vXZRJz6JBsgEdkAExY8uiDD4CvvpL3g4NldbqhHDsm28fY28thEYgKvd275bxBDg5yvh8yH2troFMneT0OHpRFwCqVHG/F21sus9hW25QfMWExgO++kyODx8fLxvOJiYbZr7rjQ/fuclBIokLt9dKVIUNkF1kyP4VCDky1Y4ccZ2XGDODoUeMM4keFGnsJGch//8nBJWNj5SzKoaF52190tGzPlpoqx3GqW9cwcRLlW3/+CbRvL3ulREYab/h4IjIp9hIysfLlgfXr5Y+NJUuAn3/O2/6WLZPJSkAAkxUirdKVoUOZrBAVQkxYDCgwEBg/Xt7/7DPZoy83UlLSRhlnV2YiAL//LifwcnJKazRGRIUKExYDmzBBjpX08iXQuXPaOEv62LpVVgm5uck2bUSFmkqVNqHRF1/IifOIqNBhwmJg1tayOsjDQ45GPWiQ/nOiqRvbDhggp0khKtS2bpXDxDs7AyNGmDsaIjITJixG4OYmB3yzsgJ++knOfqurCxeAI0fkLNADBhgvRqIsRUXJ+SAGDZITCpnT66UrX34pBy8jokKJCYuRNGmSNpPz0KEyEdHFokXyb8eOcvoNIpP55x+gZ0850Nfs2bIhVYsWwKNH5ovpt9/kLL8uLjJhIaJCiwmLEY0cCbz/vhyXpXNnOU5Ldp4+Bdatk/fZ2JZMQgg5KV2bNnKE0nXrZPe0Zs1kW5HTp4HGjWWpi6kplWmlK8OHy3kwiKjQYsJiRFZWcuj+ChXkFBv9+mXfnmXVKuDVK6BWLeCdd0wXJxVCSqUsvWjQQJai7N4t37AffwycOiWTmCNH5FwwERFyZMTcdnvLrV9+kccsXlxOtEdEhRoTFiMrVUp+7trYyMkS1Q1q01Op0qqDhg6V47kQGdyrV2lzvnz0kUxO7O3lZFXXrgGbNgH16sl1q1WTkwxWqyZHRmzcGDh50jRxKpXA5Mny/ldfySohIirUmLCYQIMGwJw58v6IEZl/5u/eDdy6JX9Mdu9u0vCoMHj8WHtW3Zs3ZQPWCRNkdc+iRZlPUufpKUta6teX+2jRAvjrL+PHu2GDLNkpWVJ2ZSaiQo8Ji4l8/rkcUyUlRZa6P3mi/by65KVPHznyOJFB3LkDhITIeskJE2QDWi8v4IcfZKIyeXLOo8aWLg3s2we0bCkHFnr/fVmdZCypqWmlK19/LbszE1Ghx4TFRBQKYMUKoHJl+R3Su7esBgJk+5Zdu+Q6gwaZN04qIC5cAHr0kKUm338PJCQAderIQYJu3JAZtD6ZsbOznNyuUycgOVlm3cuWGSf29etljKVLs/U5EWkwYTEhFxfZjsXOTs7jpq4mWrxY/m3TRiY0RLkihCwJadVKJifr18u2IO++C+zdC5w9C3TrJgf5yQ07O9nGpX9/eazPPpMz8xpy/tSUFGDKFHl/5Eg5FD8REZiwmFydOsDChfL+N9/ItivqgeX4Y5JyJTVVtuyuXz8tObGyArp2lVN9h4UB771nmJbc1tbA//4HjBkjH48ZIxvFqosL82rtWtmYy9VVtrUhIvp/CiEM+fPIfHSdntoSCCGrhH76SX7+K5Wy5P7aNfk9Q6SThARg9Wpg7lz5JQ8ADg5A375ykLWKFY17/Llz0yYi7N0bWL4896U3gKxqqloVuH1b7nv4cIOESUSWTdfv7zx8ulBuKRSyZ+mZM3K+IUD+mGSyQjp5/Fj26lm4EIiNlctKlZLtUoYMMd3kgCNGyOP26ycHHHr6VM5J4eCQu/2tXi2TFXd3YOBAQ0ZKRAUAS1jM6PJl2eXZxkb2Mi1RwtwRkUW7fRuYN0+23k5IkMu8vWXi0KcP4Ohonrh+/x3o0gVISgKaNpWP9R03JSkJqFJF9lz6/nt2ZSYqRHT9/uZvejOqXl0mLf/8w2SFsnHunBycp3JlWaqSkAC89ZYcq+T6ddn4yVzJCgAEBQF79sieRIcOAc2bAw8f6rePlStlslK2rGzMS0SUDhMWM/P0BMqXN3cUZHGEkAO0BQYCdevK5ESplI//+kvWJ3btmrc2I4bUtKlMVlxdZYL1zjuyREgXiYlpM4V+840ceZeIKJ1cJSyLFy+Gj48P7O3t4efnhyNHjmS7/qJFi+Dr6wsHBwdUrVoVa9euzXLdjRs3QqFQoEOHDrkJjSh/S02VyYmfn+zZExYmW2Z36ya7Je/ZIwdws8S5G956Czh6VA5Md/26nH/o339z3m75cuDePZm59+tn/DiJKH8Setq4caOwsbERy5YtE5cvXxbDhg0TRYsWFXfu3Ml0/cWLFwtnZ2exceNGcfPmTbFhwwbh5OQktm/fnmHd27dvi3LlyonGjRuLoKAgveKKi4sTAERcXJy+p0Rkfi9eCLFwoRDe3kLI8hUhHB2F+PxzIW7dMnd0+vnvPyGqV5fnUKKEEMeOZb1uQoIQHh5y3dBQ08VIRBZD1+9vvRvdNmjQAHXr1kVoaKhmma+vLzp06IDp06dnWD8gIACNGjXC7NmzNctCQkJw+vRpHD16VLNMqVSiadOm+PTTT3HkyBE8e/YM27ZtyzKOpKQkJCUlaR7Hx8fD09MzXzW6JcKjR7LHz48/yt4/gOzl88UXsutYqVLmjS+3njyRQ/gfPy7b12zZIge0S+/779OmDrh+HbC1NXmoRGReRml0m5ycjDNnziAwMFBreWBgIMLDwzPdJikpCfbp6qQdHBxw8uRJpKSkaJZNmTIFZcqUQd++fXWKZfr06XBxcdHcPD099TkVIvO6dUs2lvXykvPmPH4sx01ZvFjO3TB+fP5NVgA5aaG6DU5CAtC+vRwl93UJCYD6R864cUxWiChbeiUssbGxUCqVcHNz01ru5uaGmJiYTLdp1aoVli9fjjNnzkAIgdOnT2PlypVISUlB7P+PIfH3339jxYoVWKbH3CRjxoxBXFyc5nb37l19ToXIPNSNZd94Q5asvHol26v88oscOXDQIPP2+DGkokWBP/6QXZ5TUmQ7nNdKZhEaCjx4APj4AMHBZguTiPKHXHUxUKRr8CeEyLBMbfz48YiJiUHDhg0hhICbmxuCg4Mxa9YsWFtb4/nz5+jRoweWLVuG0noMeGVnZwc7O7vchE9kWkLI4fJnz5Zz/ai1aiXny2ne3DIb0RqCra2c06hkSZmgDB4sS5O+/BKYOVOuM26cHIyIiCgbepWwlC5dGtbW1hlKUx4+fJih1EXNwcEBK1euREJCAm7fvo2oqCh4e3vD2dkZpUuXxs2bN3H79m20b98eRYoUQZEiRbB27Vps374dRYoUwc2bN3N/dkTmlJIiZ0d+6y2gdWuZrFhby1mUz5+XE0m1aFFwkxU1a2tZmjR+vHw8fjwQECDb71SqBPTsad74iChf0KuExdbWFn5+fggLC8OHH36oWR4WFoagoKBst7WxsUH5/x9wZOPGjWjXrh2srKxQrVo1XLx4UWvdcePG4fnz5/j+++/ZNoXyHyFke43Ro2V7FEBWj/TvLxuYenmZNTyzUCjkLMylSsnX4J9/5PLx41m6QkQ60btKaPjw4ejZsyfq1asHf39/LF26FFFRURj4/3N/jBkzBvfu3dOMtXLt2jWcPHkSDRo0wNOnTzFv3jxcunQJa9asAQDY29ujRo0aWscoXrw4AGRYTmTxLl6Uc/ocOiQflykDDBsm26aULGne2CzBsGEyafn0U6BmTeCTT8wdERHlE3onLF26dMHjx48xZcoUREdHo0aNGti5cye8/v9XY3R0NKKiojTrK5VKzJ07FxEREbCxsUHz5s0RHh4Ob29vg50Ekdk9ewZMmiS7JyuVcrTWb76RsxnndjLAgqpHD9nl2c7OckbqJSKLx8kPifJCpZIzFY8enTZ/TseOwNy5cmJCIiLKlq7f3/x5Q5Rbp0/LsVROnJCPq1UDfvhBDqlPREQGxckPifQVGytnFH77bZmsODnJLssXLjBZISIyEpawEOlKqQT+9z85bsjTp3JZjx5yPJGyZc0bGxFRAceEhUgXR4/K3j/nz8vHtWsDCxcCjRubNSwiosKCVUJE2YmOlgObNW4sk5XixeUgaKdPM1khIjIhlrAQZSY5WTagnTwZePFCDnzWrx/w7bdybBUiIjIpJixE6YWFAV98AVy9Kh83aCDHV6lXz7xxEREVYqwSIlK7cwfo3BkIDJTJSpkywMqVQHg4kxUiIjNjwkKUmAhMnQr4+gKbN8vJ+oYNA65dk0PIW/HfhIjI3FglRIWXEMAffwBffgncuiWXNW0qe//UrGne2IiISAt/OlLhIwRw+DDQujUQFCSTlXLlgI0bgQMHmKwQEVkglrBQ4aFUAr//DsyalTacvo0NMGIEMHasHLGWiIgsEhMWKvgSE4G1a4E5c4Dr1+UyOzvZPuWrr4BKlcwbHxER5YgJCxVcT58CoaFyPJUHD+SyEiWAIUPkpIVubuaNj4iIdMaEhQqeu3eB+fOBpUuBly/lsgoVgOHDgb59WfVDRJQPMWGhguPiRTlr8oYNQGqqXFarFjByJPDxx7K9ChER5UtMWCh/EwI4dEg2pN21K2158+bAqFFyEDiFwnzxERGRQTBhofxJqQS2bpWJyqlTcpmVFdCpE/D110D9+uaNj4iIDIoJC+Uvr14Ba9bIHj83b8pl9vayx8/w4UDlyuaNj4iIjIIJC+UPT54AixfLHj+PHsllJUrI3j5DhwKuruaNj4iIjIoJC1m2O3dkj5/ly7V7/IwYAfTpwx4/RESFBBMWslxTpwKTJ8v2KgBQu7bs8fPRR+zxQ0RUyDBhIct07BgwYYK837KlTFTee489foiICikmLGR5UlOBQYPk/eBgYNUqs4ZDRETmx9mayfIsXgxcuCAb1c6aZe5oiIjIAjBhIcsSHQ2MGyfvf/cdUKaMeeMhIiKLwISFLMtXXwHPn8uB3/r3N3c0RERkIZiwkOXYvx/4+WfZsHbxYsDa2twRERGRhWDCQpYhORkYMkTeHzQIqFfPvPEQEZFFYcJClmHePODqVdlmZdo0c0dDREQWhgkLmd+dO3KQOEDOEVSihHnjISIii8OEhcwvJARISAAaNwZ69jR3NEREZIGYsJB57dgBbNsmG9guXsyRbImIKFNMWMh8Xr0CPv9c3g8JAWrUMGs4RERkuZiwkPnMmAFERgLlygETJ5o7GiIismBMWMg8rl+XCQsAzJ8PODubNx4iIrJoTFjI9ISQVUHJyUBgINC5s7kjIiIiC8eEhUxv82Zgzx7A1hb48Uc2tCUiohwxYSHTev5cNrAFgFGjgDfeMGs4RESUPzBhIdOaMgW4dw/w8QHGjDF3NERElE8wYSHTuXQJWLBA3v/hB8DBwazhEBFR/sGEhUxDCDm5YWoqEBQEtGtn7oiIiCgfYcJCprFuHXD4sCxV+f57c0dDRET5DBMWMr5nz4CvvpL3x48HvLzMGg4REeU/TFjI+MaNAx4+BKpVA0aMMHc0RESUDzFhIeM6c0ZOaggAixbJsVeIiIj0xISFjEepBAYNkg1uu3UDWrQwd0RERJRPMWEh41m+HDh1Ss4TNHeuuaMhIqJ8jAkLGcejR2kDw02dCnh4mDceIiLK15iwkHGMGgU8fQrUri3HXyEiIsoDJixkeH//DaxaJe8vXgwUKWLeeIiIKN/LVcKyePFi+Pj4wN7eHn5+fjhy5Ei26y9atAi+vr5wcHBA1apVsXbtWq3nly1bhsaNG6NEiRIoUaIE3n33XZw8eTI3oZG5paYCgwfL+336AAEB5o2HiIgKBL0Tlk2bNiEkJARjx47FuXPn0LhxY7Rp0wZRUVGZrh8aGooxY8Zg0qRJ+PfffzF58mQMGTIEf/zxh2adgwcPolu3bjhw4ACOHTuGChUqIDAwEPfu3cv9mZF5/Pgj8M8/QMmSwMyZ5o6GiIgKCIUQQuizQYMGDVC3bl2EhoZqlvn6+qJDhw6YPn16hvUDAgLQqFEjzJ49W7MsJCQEp0+fxtGjRzM9hlKpRIkSJfDjjz+iV69eOsUVHx8PFxcXxMXFoVixYvqcEhnK/ftycLjnz4H//Q/47DNzR0RERBZO1+9vvUpYkpOTcebMGQQGBmotDwwMRHh4eKbbJCUlwd7eXmuZg4MDTp48iZSUlEy3SUhIQEpKCkqWLJllLElJSYiPj9e6kZmNGCGTlbffBvr1M3c0RERUgOiVsMTGxkKpVMLNzU1ruZubG2JiYjLdplWrVli+fDnOnDkDIQROnz6NlStXIiUlBbGxsZluM3r0aJQrVw7vvvtulrFMnz4dLi4umpunp6c+p0KGtm8fsHEjYGUFhIbKv0RERAaSq28VhUKh9VgIkWGZ2vjx49GmTRs0bNgQNjY2CAoKQnBwMADA2to6w/qzZs3Chg0bsGXLlgwlM68bM2YM4uLiNLe7d+/m5lTIEJKS0rouDx4M1K1r3niIiKjA0SthKV26NKytrTOUpjx8+DBDqYuag4MDVq5ciYSEBNy+fRtRUVHw9vaGs7MzSpcurbXunDlz8N1332Hv3r2oVatWtrHY2dmhWLFiWjcyk7lzgYgIwM1NDhJHRERkYHolLLa2tvDz80NYWJjW8rCwMATk0H3VxsYG5cuXh7W1NTZu3Ih27drB6rVqg9mzZ2Pq1KnYvXs36tWrp09YZE63bwPTpsn7c+YAxYubMxoiIiqg9B7Ra/jw4ejZsyfq1asHf39/LF26FFFRURg4cCAAWVVz7949zVgr165dw8mTJ9GgQQM8ffoU8+bNw6VLl7BmzRrNPmfNmoXx48fj559/hre3t6YEx8nJCU5OToY4TzKWYcOAV6+Apk2BTz4xdzRERFRA6Z2wdOnSBY8fP8aUKVMQHR2NGjVqYOfOnfDy8gIAREdHa43JolQqMXfuXERERMDGxgbNmzdHeHg4vL29NessXrwYycnJ6Ny5s9axJk6ciEmTJuXuzCh3lEogPl4Oq5/Z7dmztPuPHgEHDsiRbBctArJox0RERJRXeo/DYqk4DksmkpKAK1eABw+yTjrS3+LjAX3fEqNGATNmGOUUiIioYNP1+5uTvBQUiYlyhNmzZ4EzZ+TfixeBLMa6yZGjI1CiRNqteHHtx+qbmxvQsqVBT4WIiCg9Jiz5UUICcOGCdnLy779yHp/0SpQAKlTIPunI7DlbW1OfFRERUZaYsFi6Fy+A8+fTkpMzZ2Q1j0qVcd3SpQE/v7Rb3bqAlxfblhARUb7HhMWSxMcD586llZqcOSPHN8msTYmbW8bkpHx5JidERFQgMWExty1bgF9/lcnJ9euZr1OunExI1ImJnx9Qtqxp4yQiIjIjJizmFB8PdOmi3fakQoW0pESdoGQxijAREVFhwYTFnK5dk8lKyZLAzz/L5KRMGXNHRUREZHGYsJiTugrozTeBVq3MGwsREZEFy9VszWQg167Jv1WqmDcOIiIiC8eExZyYsBAREemECYs5qROWN94wbxxEREQWjgmLuQiR1oaFJSxERETZYsJiLo8eAXFxcqC3SpXMHQ0REZFFY8JiLurqIC8vwN7evLEQERFZOCYs5sL2K0RERDpjwmIubL9CRESkMyYs5sIuzURERDpjwmIuTFiIiIh0xoTFHFQq4MYNeZ9tWIiIiHLEhMUc/vsPSEwEbGxkLyEiIiLKFhMWc1BXB1WqBBTh/JNEREQ5YcJiDmy/QkREpBcmLObAMViIiIj0woTFHDgGCxERkV6YsJgDq4SIiIj0woTF1JKTgchIeZ8JCxERkU6YsJhaZCSgVAJFiwIeHuaOhoiIKF9gwmJq6vYrb7wBKBTmjYWIiCifYMJiamy/QkREpDcmLKbGhIWIiEhvTFhM7fUqISIiItIJExZTYwkLERGR3piwmNLLl3LiQ4AJCxERkR6YsJjSjRvyb6lSQMmS5o2FiIgoH2HCYkpsv0JERJQrTFhMie1XiIiIcoUJiykxYSEiIsoVJiymxISFiIgoV5iwmBLbsBAREeUKExZTefIEiI2V9ytXNm8sRERE+QwTFlNRl66UKwc4OZk3FiIionyGCYupsP0KERFRrjFhMRW2XyEiIso1JiymwhIWIiKiXGPCYipMWIiIiHKNCYspCMGEhYiIKA+YsJhCTIycqdnKCvDxMXc0RERE+Q4TFlNQl674+AC2tuaNhYiIKB9iwmIKrA4iIiLKEyYspsCEhYiIKE+YsJgCx2AhIiLKEyYspsASFiIiojzJVcKyePFi+Pj4wN7eHn5+fjhy5Ei26y9atAi+vr5wcHBA1apVsXbt2gzrbN68GdWrV4ednR2qV6+OrVu35iY0y6NUAjduyPtMWIiIiHJF74Rl06ZNCAkJwdixY3Hu3Dk0btwYbdq0QVRUVKbrh4aGYsyYMZg0aRL+/fdfTJ48GUOGDMEff/yhWefYsWPo0qULevbsiQsXLqBnz574+OOPceLEidyfmaW4cwdISQHs7ABPT3NHQ0RElC8phBBCnw0aNGiAunXrIjQ0VLPM19cXHTp0wPTp0zOsHxAQgEaNGmH27NmaZSEhITh9+jSOHj0KAOjSpQvi4+Oxa9cuzTqtW7dGiRIlsGHDBp3iio+Ph4uLC+Li4lCsWDF9Tsm49uwBWrcG3nwTuHTJ3NEQERFZFF2/v/UqYUlOTsaZM2cQGBiotTwwMBDh4eGZbpOUlAR7e3utZQ4ODjh58iRSUlIAyBKW9Pts1apVlvtU7zc+Pl7rZpHYfoWIiCjP9EpYYmNjoVQq4ebmprXczc0NMTExmW7TqlUrLF++HGfOnIEQAqdPn8bKlSuRkpKC2NhYAEBMTIxe+wSA6dOnw8XFRXPztNTqFiYsREREeZarRrcKhULrsRAiwzK18ePHo02bNmjYsCFsbGwQFBSE4OBgAIC1tXWu9gkAY8aMQVxcnOZ29+7d3JyK8akTFnZpJiIiyjW9EpbSpUvD2to6Q8nHw4cPM5SQqDk4OGDlypVISEjA7du3ERUVBW9vbzg7O6N06dIAAHd3d732CQB2dnYoVqyY1s0iqcdgYQkLERFRrumVsNja2sLPzw9hYWFay8PCwhAQEJDttjY2Nihfvjysra2xceNGtGvXDlZW8vD+/v4Z9rl3794c92nxkpKA27flfSYsREREuVZE3w2GDx+Onj17ol69evD398fSpUsRFRWFgQMHApBVNffu3dOMtXLt2jWcPHkSDRo0wNOnTzFv3jxcunQJa9as0exz2LBhaNKkCWbOnImgoCD8/vvv+OuvvzS9iPKtmzcBIYBixQBXV3NHQ0RElG/pnbB06dIFjx8/xpQpUxAdHY0aNWpg586d8PLyAgBER0drjcmiVCoxd+5cREREwMbGBs2bN0d4eDi8vb016wQEBGDjxo0YN24cxo8fj0qVKmHTpk1o0KBB3s/QnF4fkj+b9jhERESUPb3HYbFUFjkOy+zZwMiRQLduwM8/mzsaIiIii2OUcVhIT+zSTEREZBBMWIyJCQsREZFBMGExptfbsBAREVGuMWExlufPgehoeZ8JCxERUZ4wYTEWdemKqytQvLhZQyEiIsrvmLAYC9uvEBERGQwTFmNh+xUiIiKDYcJiLCxhISIiMhgmLMbChIWIiMhgmLAYgxBMWIiIiAyICYsxPH4MPHsm71eqZNZQiIiICgImLMagLl2pUAFwcDBvLERERAUAExZjYHUQERGRQTFhMQYmLERERAbFhMUYOAYLERGRQTFhMQaWsBARERkUExZDU6nSSliYsBARERkEExZDu3cPePUKKFIE8PY2dzREREQFAhMWQ1OXrlSsKJMWIiIiyjMmLIbG9itEREQGx4TF0JiwEBERGRwTFkNjwkJERGRwTFgMjWOwEBERGRwTFkNKSQFu3ZL3WcJCRERkMExYDOn2bSA1FXB0BMqWNXc0REREBQYTFkN6vTrIii8tERGRofBb1ZDUDW7ZfoWIiMigmLAYEnsIERERGQUTFkNiwkJERGQUTFgMiZMeEhERGQUTFkN59QqIipL32YaFiIjIoJiwGMqNG/JviRJAqVLmjYWIiKiAYcJiKK+3X1EozBsLERFRAcOExVA4JD8REZHRMGExFPYQIiIiMhomLIbChIWIiMhomLAYChMWIiIio2HCYgjPngGPHsn7lSubNRQiIqKCiAmLIagb3Hp4AM7O5o2FiIioAGLCYgisDiIiIjIqJiyGwISFiIjIqJiwGALHYCEiIjIqJiyGwBIWIiIio2LCkldCMGEhIiIyMiYsefXgAfD8OWBlBVSsaO5oiIiICiQmLHmlbr/i5QXY2Zk3FiIiogKKCUtesTqIiIjI6Jiw5BUTFiIiIqNjwpJXTFiIiIiMjglLXnEMFiIiIqNjwpIXSiVw44a8zxIWIiIio8lVwrJ48WL4+PjA3t4efn5+OHLkSLbrr1+/HrVr14ajoyM8PDzw6aef4vHjx1rrLFiwAFWrVoWDgwM8PT3x5ZdfIjExMTfhmc7du0BSEmBrC1SoYO5oiIiICiy9E5ZNmzYhJCQEY8eOxblz59C4cWO0adMGUVFRma5/9OhR9OrVC3379sW///6LX3/9FadOnUK/fv0066xfvx6jR4/GxIkTceXKFaxYsQKbNm3CmDFjcn9mpqBuv1K5MmBtbd5YiIiICjC9E5Z58+ahb9++6NevH3x9fbFgwQJ4enoiNDQ00/WPHz8Ob29vfPHFF/Dx8cE777yDAQMG4PTp05p1jh07hkaNGqF79+7w9vZGYGAgunXrprWORWL7FSIiIpPQK2FJTk7GmTNnEBgYqLU8MDAQ4eHhmW4TEBCA//77Dzt37oQQAg8ePMBvv/2G999/X7POO++8gzNnzuDkyZMAgFu3bmHnzp1a66SXlJSE+Ph4rZvJsYcQERGRSRTRZ+XY2FgolUq4ublpLXdzc0NMTEym2wQEBGD9+vXo0qULEhMTkZqaig8++AALFy7UrNO1a1c8evQI77zzDoQQSE1NxaBBgzB69OgsY5k+fTomT56sT/iGx4SFiIjIJHLV6FahUGg9FkJkWKZ2+fJlfPHFF5gwYQLOnDmD3bt3IzIyEgMHDtSsc/DgQXz77bdYvHgxzp49iy1btuDPP//E1KlTs4xhzJgxiIuL09zu3r2bm1PJG3WVEBMWIiIio9KrhKV06dKwtrbOUJry8OHDDKUuatOnT0ejRo3w9ddfAwBq1aqFokWLonHjxpg2bRo8PDwwfvx49OzZU9MQt2bNmnj58iU+++wzjB07FlZWGfMqOzs72Jlz7p7kZCAyUt5nGxYiIiKj0quExdbWFn5+fggLC9NaHhYWhoCAgEy3SUhIyJBwWP9/jxohRLbrCCE061icW7cAlQpwcgLc3c0dDRERUYGmVwkLAAwfPhw9e/ZEvXr14O/vj6VLlyIqKkpTxTNmzBjcu3cPa9euBQC0b98e/fv3R2hoKFq1aoXo6GiEhITg7bffRtmyZTXrzJs3D2+99RYaNGiAGzduYPz48fjggw80yY3Feb39ShbVYURERGQYeicsXbp0wePHjzFlyhRER0ejRo0a2LlzJ7y8vAAA0dHRWmOyBAcH4/nz5/jxxx8xYsQIFC9eHC1atMDMmTM164wbNw4KhQLjxo3DvXv3UKZMGbRv3x7ffvutAU7RSNh+hYiIyGQUwmLrXPQTHx8PFxcXxMXFoVixYsY/4IABwNKlwPjxwJQpxj8eERFRAaTr9zfnEsotdmkmIiIyGSYsucWEhYiIyGSYsOTGixfA/fvyPrs0ExERGR0Tlty4cUP+LV0aKFHCvLEQEREVAnr3EiKwOoiIDE6lUiE5OdncYRAZnI2NjUGGKGHCkhtMWIjIgJKTkxEZGQmVSmXuUIiMonjx4nB3d89yGh9dMGHJDY7BQkQGIoRAdHQ0rK2t4enpmelUJET5lRACCQkJePjwIQDAw8Mj1/tiwpIb6hIWNrglojxKTU1FQkICypYtC0dHR3OHQ2RwDg4OAOS8g66urrmuHmIqnxusEiIiA1EqlQDkXG1EBZU6GU9JScn1Ppiw6OvxY+DJE3m/cmXzxkJEBUZe6vaJLJ0h3t9MWPSlbr/i6Qmw+JaIiMgkmLDoi+1XiIiMolmzZggJCdF5/du3b0OhUOD8+fNGi4ksBxvd6ovtV4iokMupeL93795YvXq13vvdsmULbGxsdF7f09MT0dHRKF26tN7HovyHCYu+mLAQUSEXHR2tub9p0yZMmDABERERmmXqXiFqKSkpOiUiJUuW1CsOa2truLu767VNQZGcnFzoGmqzSkhf6jYsrBIiokLK3d1dc3NxcYFCodA8TkxMRPHixfHLL7+gWbNmsLe3x7p16/D48WN069YN5cuXh6OjI2rWrIkNGzZo7Td9lZC3tze+++479OnTB87OzqhQoQKWLl2qeT59ldDBgwehUCiwb98+1KtXD46OjggICNBKpgBg2rRpcHV1hbOzM/r164fRo0ejTp06WZ6vUqlE37594ePjAwcHB1StWhXff/99hvVWrlyJN998E3Z2dvDw8MDQoUM1zz179gyfffYZ3NzcYG9vjxo1auDPP/8EAEyaNCnD8RcsWABvb2/N4+DgYHTo0AHTp09H2bJlUeX/fzSvW7cO9erVg7OzM9zd3dG9e3fNmCdq//77L95//30UK1YMzs7OaNy4MW7evInDhw/DxsYGMTExWuuPGDECTZo0yfL1MBcmLPoQgiUsRGRcQgAvX5rnJoTBTmPUqFH44osvcOXKFbRq1QqJiYnw8/PDn3/+iUuXLuGzzz5Dz549ceLEiWz3M3fuXNSrVw/nzp3D4MGDMWjQIFy9ejXbbcaOHYu5c+fi9OnTKFKkCPr06aN5bv369fj2228xc+ZMnDlzBhUqVEBoaGi2+1OpVChfvjx++eUXXL58GRMmTMA333yDX375RbNOaGgohgwZgs8++wwXL17E9u3bUfn/e5KqVCq0adMG4eHhWLduHS5fvowZM2boPR7Jvn37cOXKFYSFhWmSneTkZEydOhUXLlzAtm3bEBkZieDgYM029+7dQ5MmTWBvb4/9+/fjzJkz6NOnD1JTU9GkSRNUrFgRP/30k2b91NRUrFu3Dp9++qlesZmEKCDi4uIEABEXF2e8g/z3nxCAENbWQiQnG+84RFRovHr1Sly+fFm8evVKLnjxQn7OmOP24oXe8a9atUq4uLhoHkdGRgoAYsGCBTlu27ZtWzFixAjN46ZNm4phw4ZpHnt5eYkePXpoHqtUKuHq6ipCQ0O1jnXu3DkhhBAHDhwQAMRff/2l2WbHjh0CgOb1bdCggRgyZIhWHI0aNRK1a9fW9ZSFEEIMHjxYdOrUSfO4bNmyYuzYsZmuu2fPHmFlZSUiIiIyfX7ixIkZjj9//nzh5eWledy7d2/h5uYmkpKSso3r5MmTAoB4/vy5EEKIMWPGCB8fH5GcxXfWzJkzha+vr+bxtm3bhJOTk3iRi/dCdjK8z1+j6/c3S1j0oS5dqVgR0KNhGBFRYVOvXj2tx0qlEt9++y1q1aqFUqVKwcnJCXv37kVUVFS2+6lVq5bmvrrqKX2VR3bbqIeCV28TERGBt99+W2v99I8zs2TJEtSrVw9lypSBk5MTli1bpon94cOHuH//Plq2bJnptufPn0f58uU11Ti5VbNmzQztVs6dO4egoCB4eXnB2dkZzZo1AwBNbOfPn0fjxo2zbEMUHByMGzdu4Pjx4wBktdbHH3+MokWL5ilWY2CjW32w/QoRGZujI/DihfmObSDpv/Dmzp2L+fPnY8GCBahZsyaKFi2KkJCQHGeoTv9Fq1Aocpwk8vVt1D2aXt8mfS8nkUNV2C+//IIvv/wSc+fOhb+/P5ydnTF79mxNdVb6Rsbp5fS8lZVVhhgyGxE2/Wv68uVLBAYGIjAwEOvWrUOZMmUQFRWFVq1aaV7XnI7t6uqK9u3bY9WqVahYsSJ27tyJgwcPZruNuTBh0QfbrxCRsSkUgAX+us2rI0eOICgoCD169AAgE4jr16/D19fXpHFUrVoVJ0+eRM+ePTXLTp8+ne02R44cQUBAAAYPHqxZdvPmTc19Z2dneHt7Y9++fWjevHmG7WvVqoX//vsP165dy7SUpUyZMoiJiYEQQpNM6TK2zNWrVxEbG4sZM2bA09Mz03OpVasW1qxZk21PrX79+qFr164oX748KlWqhEaNGuV4bHNglZA+mLAQEeVK5cqVERYWhvDwcFy5cgUDBgzI0DvFFD7//HOsWLECa9aswfXr1zFt2jT8888/2Y4tU7lyZZw+fRp79uzBtWvXMH78eJw6dUprnUmTJmHu3Ln44YcfcP36dZw9exYLFy4EADRt2hRNmjRBp06dEBYWhsjISOzatQu7d+8GIHtHPXr0CLNmzcLNmzexaNEi7Nq1K8dzqVChAmxtbbFw4ULcunUL27dvx9SpU7XWGTp0KOLj49G1a1ecPn0a169fx08//aTVc6pVq1ZwcXHBtGnTLLOx7f9jwqIPJixERLkyfvx41K1bF61atUKzZs3g7u6ODh06mDyOTz75BGPGjMFXX32FunXranrV2NvbZ7nNwIED0bFjR3Tp0gUNGjTA48ePtUpbADlY3oIFC7B48WK8+eabaNeuHa6rmxEA2Lx5M+rXr49u3bqhevXqGDlypGbiS19fXyxevBiLFi1C7dq1cfLkSXz11Vc5nkuZMmWwevVq/Prrr6hevTpmzJiBOXPmaK1TqlQp7N+/Hy9evEDTpk3h5+eHZcuWaZW2WFlZITg4GEqlEr169dLpdTQHhcip8i6fiI+Ph4uLC+Li4lCsWDHDHyA1VdbvpqQAd+4AFSoY/hhEVOgkJiYiMjISPj4+2X5pkvG89957cHd31+reW9j0798fDx48wPbt242y/+ze57p+f7MNi67u3JHJir09UL68uaMhIqJcSEhIwJIlS9CqVStYW1tjw4YN+OuvvxAWFmbu0MwiLi4Op06dwvr16/H777+bO5xsMWHR1euTHlqxJo2IKD9SKBTYuXMnpk2bhqSkJFStWhWbN2/Gu+++a+7QzCIoKAgnT57EgAED8N5775k7nGwxYdGVui6S7VeIiPItBwcH/PXXX+YOw2JYahfmzLCoQFevl7AQERGRSTFh0RV7CBEREZkNExZdMWEhIiIyGyYsukhMBNTzXTBhISIiMjkmLLq4eVPOZeriApQube5oiIiICh0mLLp4vToom+GbiYiIyDiYsOiC7VeIiAyuWbNmCAkJ0Tz29vbGggULst1GoVBg27ZteT62ofZDpsOERRccg4WISKN9+/ZZDrR27NgxKBQKnD17Vu/9njp1Cp999llew9MyadIk1KlTJ8Py6OhotGnTxqDHIuNiwqILjsFCRKTRt29f7N+/H3fu3Mnw3MqVK1GnTh3UrVtX7/2WKVMGjo6OhggxR+7u7rCzszPJsSxJcnKyuUPINSYsumCVEBGRRrt27eDq6orVq1drLU9ISMCmTZvQt29fPH78GN26dUP58uXh6OiImjVrYsOGDdnuN32V0PXr19GkSRPY29ujevXqmc73M2rUKFSpUgWOjo6oWLEixo8fj5SUFADA6tWrMXnyZFy4cAEKhQIKhUITc/oqoYsXL6JFixZwcHBAqVKl8Nlnn+HFixea54ODg9GhQwfMmTMHHh4eKFWqFIYMGaI5VmZu3ryJoKAguLm5wcnJCfXr188wym5SUhJGjhwJT09P2NnZ4Y033sCKFSs0z//77794//33UaxYMTg7O6Nx48a4efMmgIxVagDQoUMHBAcHa72m06ZNQ3BwMFxcXNC/f/8cXze17du3o169erC3t0fp0qXRsWNHAMCUKVNQs2bNDOfr5+eHCRMmZPl65BWH5s9JfDzw4IG8zxIWIjIyIYCEBPMc29FRt34FRYoUQa9evbB69WpMmDABiv/f6Ndff0VycjI++eQTJCQkwM/PD6NGjUKxYsWwY8cO9OzZExUrVkSDBg1yPIZKpULHjh1RunRpHD9+HPHx8Rm+nAHA2dkZq1evRtmyZXHx4kX0798fzs7OGDlyJLp06YJLly5h9+7dmkTBxcUlwz4SEhLQunVrNGzYEKdOncLDhw/Rr18/DB06VCspO3DgADw8PHDgwAHcuHEDXbp0QZ06dTRJQHovXrxA27ZtMW3aNNjb22PNmjVo3749IiIiUKFCBQBAr169cOzYMfzwww+oXbs2IiMjERsbCwC4d+8emjRpgmbNmmH//v0oVqwY/v77b6Smpub4+r1u9uzZGD9+PMaNG6fT6wYAO3bsQMeOHTF27Fj89NNPSE5Oxo4dOwAAffr0weTJk3Hq1CnUr18fAPDPP//g3Llz+PXXX/WKTS+igIiLixMARFxcnGF3fPq0EIAQ7u6G3S8RkRDi1atX4vLly+LVq1dCCCFevJAfOea4vXihe9xXrlwRAMT+/fs1y5o0aSK6deuW5TZt27YVI0aM0Dxu2rSpGDZsmOaxl5eXmD9/vhBCiD179ghra2tx9+5dzfO7du0SAMTWrVuzPMasWbOEn5+f5vHEiRNF7dq1M6z3+n6WLl0qSpQoIV689gLs2LFDWFlZiZiYGCGEEL179xZeXl4iNTVVs85HH30kunTpkmUsmalevbpYuHChEEKIiIgIAUCEhYVluu6YMWOEj4+PSE5OzvT59K+fEEIEBQWJ3r17ax57eXmJDh065BhX+tfN399ffPLJJ1mu36ZNGzFo0CDN45CQENGsWbMs10//Pn+drt/frBLKCduvEBFlUK1aNQQEBGDlypUAZPXHkSNH0KdPHwCAUqnEt99+i1q1aqFUqVJwcnLC3r17EaUehDMHV65cQYUKFVC+fHnNMn9//wzr/fbbb3jnnXfg7u4OJycnjB8/XudjvH6s2rVro2jRoppljRo1gkqlQkREhGbZm2++CWtra81jDw8PPHz4MMv9vnz5EiNHjkT16tVRvHhxODk54erVq5r4zp8/D2trazRt2jTT7c+fP4/GjRvDxsZGr/NJr169ehmW5fS6nT9/Hi1btsxyn/3798eGDRuQmJiIlJQUrF+/XnPtjYVVQjlh+xUiMiFHR+C1phMmP7Y++vbti6FDh2LRokVYtWoVvLy8NF9yc+fOxfz587FgwQLUrFkTRYsWRUhIiM6NPoUQGZYp0tVXHT9+HF27dsXkyZPRqlUruLi4YOPGjZg7d65e5yGEyLDvzI6ZPnFQKBRQqVRZ7vfrr7/Gnj17MGfOHFSuXBkODg7o3Lmz5jVwcHDINq6cnreyssrwOmXWpub1RAzQ7XXL6djt27eHnZ0dtm7dCjs7OyQlJaFTp07ZbpNXTFhywoSFiExIoQDSfb9YrI8//hjDhg3Dzz//jDVr1qB///6aL/gjR44gKCgIPXr0ACDbpFy/fh2+vr467bt69eqIiorC/fv3UbZsWQCyy/Tr/v77b3h5eWHs2LGaZel7Ltna2kKpVOZ4rDVr1uDly5eaL/e///4bVlZWqJKHz/4jR44gODgYH374IQDZpuX27dua52vWrAmVSoVDhw5l2k28Vq1aWLNmDVJSUjItZSlTpgyio6M1j5VKJS5duoTmzZtnG5cur1utWrWwb98+fPrpp5nuo0iRIujduzdWrVoFOzs7dO3a1eg9vFgllBOOwUJElCknJyd06dIF33zzDe7fv6/VO6Vy5coICwtDeHg4rly5ggEDBiAmJkbnfb/77ruoWrUqevXqhQsXLuDIkSNaX7DqY0RFRWHjxo24efMmfvjhB2zdulVrHW9vb0RGRuL8+fOIjY1FUlJShmN98sknsLe3R+/evXHp0iUcOHAAn3/+OXr27Ak3Nzf9XpR08W3ZsgXnz5/HhQsX0L17d60SGW9vb/Tu3Rt9+vTBtm3bEBkZiYMHD+KXX34BAAwdOhTx8fHo2rUrTp8+jevXr+Onn37SVFO1aNECO3bswI4dO3D16lUMHjwYz5490ymunF63iRMnYsOGDZg4cSKuXLmCixcvYtasWVrr9OvXD/v378euXbuMXh0EMGHJ2aBBwLBhQCYDDxERFXZ9+/bF06dP8e6772p6vgDA+PHjUbduXbRq1QrNmjWDu7s7OnTooPN+rayssHXrViQlJeHtt99Gv3798O2332qtExQUhC+//BJDhw5FnTp1EB4ejvHjx2ut06lTJ7Ru3RrNmzdHmTJlMu1a7ejoiD179uDJkyeoX78+OnfujJYtW+LHH3/U78VIZ/78+ShRogQCAgLQvn17tGrVKsP4NKGhoejcuTMGDx6MatWqoX///nj58iUAoFSpUti/fz9evHiBpk2bws/PD8uWLdOUtvTp0we9e/dGr1690LRpU/j4+ORYugLo9ro1a9YMv/76K7Zv3446deqgRYsWOHHihNY6b7zxBgICAlC1alWden7llUJkVlGYD8XHx8PFxQVxcXEoVqyYucMhItJJYmIiIiMj4ePjA3t7e3OHQ6QzIQSqVauGAQMGYPjw4dmum937XNfvb7ZhISIiIr08fPgQP/30E+7du5dlOxdDY8JCREREenFzc0Pp0qWxdOlSlChRwiTHZMJCREREejFHaxI2uiUiIiKLx4SFiIiILB4TFiIiC1BAOmwSZSq7EYF1xTYsRERmZGNjA4VCgUePHqFMmTJZDhFPlB8JIZCcnIxHjx7BysoKtra2ud4XExYiIjOytrZG+fLl8d9//2kN205UkDg6OqJChQqwssp9xU6uEpbFixdj9uzZiI6OxptvvokFCxagcePGWa6/fv16zJo1C9evX4eLiwtat26NOXPmoFSpUpp1nj17hrFjx2LLli14+vQpfHx8MHfuXLRt2zY3IRIR5RtOTk544403Mp24jii/s7a2RpEiRfJceqh3wrJp0yaEhIRg8eLFaNSoEf73v/+hTZs2uHz5stawzGpHjx5Fr169MH/+fLRv3x737t3DwIED0a9fP83cBcnJyXjvvffg6uqK3377DeXLl8fdu3fh7Oycp5MjIsovrK2tYW1tbe4wiCyW3kPzN2jQAHXr1kVoaKhmma+vLzp06IDp06dnWH/OnDkIDQ3FzZs3NcsWLlyIWbNm4e7duwCAJUuWYPbs2bh69WqmM1LqgkPzExER5T+6fn/rVZmUnJyMM2fOIDAwUGt5YGAgwsPDM90mICAA//33H3bu3AkhBB48eIDffvsN77//vmad7du3w9/fH0OGDIGbmxtq1KiB7777LtspwZOSkhAfH691IyIiooJJr4QlNjYWSqUyw3Tbbm5uWU4bHhAQgPXr16NLly6wtbWFu7s7ihcvjoULF2rWuXXrFn777TcolUrs3LkT48aNw9y5czPMzPm66dOnw8XFRXPz9PTU51SIiIgoH8lVo9v0DWeEEFk2prl8+TK++OILTJgwAa1atUJ0dDS+/vprDBw4ECtWrAAg+2e7urpi6dKlsLa2hp+fH+7fv4/Zs2djwoQJme53zJgxWrNDxsXFoUKFCixpISIiykfU39s5tVDRK2EpXbo0rK2tM5SmPHz4MEOpi9r06dPRqFEjfP311wCAWrVqoWjRomjcuDGmTZsGDw8PeHh4wMbGRqvBma+vL2JiYpCcnJxpv207OzvY2dlpHqtPmCUtRERE+c/z58/h4uKS5fN6JSy2trbw8/NDWFgYPvzwQ83ysLAwBAUFZbpNQkICihTRPow6MVFnU40aNcLPP/8MlUql6aN97do1eHh46DzITNmyZTU9iww58FJ8fDw8PT1x9+7dQtGYtzCdL8+14CpM58tzLbgKy/kKIfD8+XOULVs22/X0rhIaPnw4evbsiXr16sHf3x9Lly5FVFQUBg4cCEBW1dy7dw9r164FALRv3x79+/dHaGiopkooJCQEb7/9tia4QYMGYeHChRg2bBg+//xzXL9+Hd999x2++OILneOysrJC+fLl9T0dnRUrVqxAv2HSK0zny3MtuArT+fJcC67CcL7Zlayo6Z2wdOnSBY8fP8aUKVMQHR2NGjVqYOfOnfDy8gIAREdHIyoqSrN+cHAwnj9/jh9//BEjRoxA8eLF0aJFC8ycOVOzjqenJ/bu3Ysvv/wStWrVQrly5TBs2DCMGjVK3/CIiIioANJ7HJbCprCN71KYzpfnWnAVpvPluRZche18c8LZmnNgZ2eHiRMnajXwLcgK0/nyXAuuwnS+PNeCq7Cdb05YwkJEREQWjyUsREREZPGYsBAREZHFY8JCREREFo8JCxEREVk8JixERERk8ZiwAFi8eDF8fHxgb28PPz8/HDlyJNv1Dx06BD8/P9jb26NixYpYsmSJiSLNm+nTp6N+/fpwdnaGq6srOnTogIiIiGy3OXjwIBQKRYbb1atXTRR17kyaNClDzO7u7tluk1+vq7e3d6bXaMiQIZmun9+u6eHDh9G+fXuULVsWCoUC27Zt03peCIFJkyahbNmycHBwQLNmzfDvv//muN/NmzejevXqsLOzQ/Xq1bF161YjnYHusjvXlJQUjBo1CjVr1kTRokVRtmxZ9OrVC/fv3892n6tXr870eicmJhr5bLKX03UNDg7OEHPDhg1z3K8lXlcg5/PN7BopFArMnj07y31a6rU1lkKfsGzatAkhISEYO3Yszp07h8aNG6NNmzZao/W+LjIyEm3btkXjxo1x7tw5fPPNN/jiiy+wefNmE0euv0OHDmHIkCE4fvw4wsLCkJqaisDAQLx8+TLHbSMiIhAdHa25vfHGGyaIOG/efPNNrZgvXryY5br5+bqeOnVK6zzDwsIAAB999FG22+WXa/ry5UvUrl0bP/74Y6bPz5o1C/PmzcOPP/6IU6dOwd3dHe+99x6eP3+e5T6PHTuGLl26oGfPnrhw4QJ69uyJjz/+GCdOnDDWaegku3NNSEjA2bNnMX78eJw9exZbtmzBtWvX8MEHH+S432LFimld6+joaNjb2xvjFHSW03UFgNatW2vFvHPnzmz3aanXFcj5fNNfn5UrV0KhUKBTp07Z7tcSr63RiELu7bffFgMHDtRaVq1aNTF69OhM1x85cqSoVq2a1rIBAwaIhg0bGi1GY3n48KEAIA4dOpTlOgcOHBAAxNOnT00XmAFMnDhR1K5dW+f1C9J1HTZsmKhUqZJQqVSZPp9fr6kQQgAQW7du1TxWqVTC3d1dzJgxQ7MsMTFRuLi4iCVLlmS5n48//li0bt1aa1mrVq1E165dDR5zbqU/18ycPHlSABB37tzJcp1Vq1YJFxcXwwZnYJmda+/evUVQUJBe+8kP11UI3a5tUFCQaNGiRbbr5Idra0iFuoQlOTkZZ86cQWBgoNbywMBAhIeHZ7rNsWPHMqzfqlUrnD59GikpKUaL1Rji4uIAACVLlsxx3bfeegseHh5o2bIlDhw4YOzQDOL69esoW7YsfHx80LVrV9y6dSvLdQvKdU1OTsa6devQp0+fHGctz4/XNL3IyEjExMRoXTs7Ozs0bdo0y/9hIOvrnd02liguLg4KhQLFixfPdr0XL17Ay8sL5cuXR7t27XDu3DnTBJhHBw8ehKurK6pUqYL+/fvj4cOH2a5fUK7rgwcPsGPHDvTt2zfHdfPrtc2NQp2wxMbGQqlUws3NTWu5m5sbYmJiMt0mJiYm0/VTU1MRGxtrtFgNTQiB4cOH45133kGNGjWyXM/DwwNLly7F5s2bsWXLFlStWhUtW7bE4cOHTRit/ho0aIC1a9diz549WLZsGWJiYhAQEIDHjx9nun5Bua7btm3Ds2fPEBwcnOU6+fWaZkb9f6rP/7B6O323sTSJiYkYPXo0unfvnu08M9WqVcPq1auxfft2bNiwAfb29mjUqBGuX79uwmj116ZNG6xfvx779+/H3LlzcerUKbRo0QJJSUlZblMQrisArFmzBs7OzujYsWO26+XXa5tbes/WXBCl/yUqhMj212lm62e23JINHToU//zzD44ePZrtelWrVkXVqlU1j/39/XH37l3MmTMHTZo0MXaYudamTRvN/Zo1a8Lf3x+VKlXCmjVrMHz48Ey3KQjXdcWKFWjTpg3Kli2b5Tr59ZpmR9//4dxuYylSUlLQtWtXqFQqLF68ONt1GzZsqNVYtVGjRqhbty4WLlyIH374wdih5lqXLl0092vUqIF69erBy8sLO3bsyPaLPD9fV7WVK1fik08+ybEtSn69trlVqEtYSpcuDWtr6wzZ98OHDzNk6Wru7u6Zrl+kSBGUKlXKaLEa0ueff47t27fjwIEDKF++vN7bN2zYMN9l8EWLFkXNmjWzjLsgXNc7d+7gr7/+Qr9+/fTeNj9eUwCanl/6/A+rt9N3G0uRkpKCjz/+GJGRkQgLC9N7Fl8rKyvUr18/311vDw8PeHl5ZRt3fr6uakeOHEFERESu/o/z67XVVaFOWGxtbeHn56fpVaEWFhaGgICATLfx9/fPsP7evXtRr1492NjYGC1WQxBCYOjQodiyZQv2798PHx+fXO3n3Llz8PDwMHB0xpWUlIQrV65kGXd+vq5qq1atgqurK95//329t82P1xQAfHx84O7urnXtkpOTcejQoSz/h4Gsr3d221gCdbJy/fp1/PXXX7lKpoUQOH/+fL673o8fP8bdu3ezjTu/XtfXrVixAn5+fqhdu7be2+bXa6szc7X2tRQbN24UNjY2YsWKFeLy5csiJCREFC1aVNy+fVsIIcTo0aNFz549NevfunVLODo6ii+//FJcvnxZrFixQtjY2IjffvvNXKegs0GDBgkXFxdx8OBBER0drbklJCRo1kl/vvPnzxdbt24V165dE5cuXRKjR48WAMTmzZvNcQo6GzFihDh48KC4deuWOH78uGjXrp1wdnYukNdVCCGUSqWoUKGCGDVqVIbn8vs1ff78uTh37pw4d+6cACDmzZsnzp07p+kZM2PGDOHi4iK2bNkiLl68KLp16yY8PDxEfHy8Zh89e/bU6vn3999/C2trazFjxgxx5coVMWPGDFGkSBFx/Phxk5/f67I715SUFPHBBx+I8uXLi/Pnz2v9DyclJWn2kf5cJ02aJHbv3i1u3rwpzp07Jz799FNRpEgRceLECXOcokZ25/r8+XMxYsQIER4eLiIjI8WBAweEv7+/KFeuXL68rkLk/D4WQoi4uDjh6OgoQkNDM91Hfrm2xlLoExYhhFi0aJHw8vIStra2om7dulrdfHv37i2aNm2qtf7BgwfFW2+9JWxtbYW3t3eWby5LAyDT26pVqzTrpD/fmTNnikqVKgl7e3tRokQJ8c4774gdO3aYPng9denSRXh4eAgbGxtRtmxZ0bFjR/Hvv/9qni9I11UIIfbs2SMAiIiIiAzP5fdrqu6Gnf7Wu3dvIYTs2jxx4kTh7u4u7OzsRJMmTcTFixe19tG0aVPN+mq//vqrqFq1qrCxsRHVqlWziIQtu3ONjIzM8n/4wIEDmn2kP9eQkBBRoUIFYWtrK8qUKSMCAwNFeHi46U8unezONSEhQQQGBooyZcoIGxsbUaFCBdG7d28RFRWltY/8cl2FyPl9LIQQ//vf/4SDg4N49uxZpvvIL9fWWBRC/H/LQiIiIiILVajbsBAREVH+wISFiIiILB4TFiIiIrJ4TFiIiIjI4jFhISIiIovHhIWIiIgsHhMWIiIisnhMWIiIiMjiMWEhIiIii8eEhYiIiCweExYiIiKyeP8Hyp09CxHybUkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scenario described by Andrew Ng's Coursera course, using `include_top = False` and `weights = None` together is actually very strategic and not redundant when followed by loading specific pretrained weights (`weights=path`) and freezing the layers. This approach combines several techniques to leverage a pre-trained model effectively for a new, related task through transfer learning. Let’s break down the steps and the rationale behind each:\n",
    "\n",
    "### Step-by-Step Analysis\n",
    "\n",
    "1. **Setting `include_top = False`**:\n",
    "    - This setting is used to remove the original top layers (usually dense layers) that were specific to the classification tasks for which the model was initially trained (like the 1000-class prediction in ImageNet).\n",
    "    - It allows you to replace these with layers that are better suited to your specific task, which in this context involves classifying images as either cats or dogs.\n",
    "\n",
    "2. **Setting `weights = None`**:\n",
    "    - Initially, this configuration specifies that the model should not automatically load the default pretrained weights at the time of initialization.\n",
    "    - This gives you control over which weights the model starts with, allowing for more flexibility, especially if you plan to load a different set of weights or modify the initialization in some way.\n",
    "\n",
    "3. **Loading Specific Pretrained Weights**:\n",
    "    - After initializing the model with `weights = None`, the course instructs to manually load pretrained weights with `pre_trained_model.load_weights(path)`.\n",
    "    - These weights are specifically the convolutional base of InceptionV3 without the top layers (`_notop`), tailored for feature extraction rather than for a specific classification task.\n",
    "    - This step ensures that you're using a robust feature extractor trained on a broad dataset like ImageNet, but without the final classification layers that don't pertain to your task.\n",
    "\n",
    "4. **Freezing the Convolutional Base**:\n",
    "    - The next step is to freeze the layers of this model by setting `layer.trainable = False`. This is crucial because it preserves the generic features these layers have learned, which are generally applicable to a wide range of image recognition tasks.\n",
    "    - Freezing prevents the pretrained weights from being updated during training. This is important when your dataset is relatively small or not diverse enough to retrain a deep network without overfitting.\n",
    "\n",
    "5. **Adding Custom Dense Layers**:\n",
    "    - On top of the frozen convolutional base, new trainable layers are added. These layers are designed to learn features specific to the new dataset (cats and dogs in this example).\n",
    "    - This approach allows for customization where the new data's specific features dictate the learning in these top layers, while the broad features extracted from the generic dataset are retained in the frozen layers.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This methodology is a classic example of transfer learning, where you take a pre-trained model, repurpose the feature-extracting layers, and then train a new classifier on top for a different but related task. It’s efficient because:\n",
    "- **Speed**: You skip the time-consuming and computationally expensive process of training the convolutional layers from scratch.\n",
    "- **Performance**: You leverage the advanced feature-detecting capabilities of a model trained on a much larger dataset.\n",
    "- **Resource Management**: It’s resource-efficient, requiring less data and computational power to achieve high accuracy.\n",
    "\n",
    "In essence, the `weights=None` initially followed by loading specific weights and freezing layers is a deliberate strategy to harness the strength of pre-existing models while tailoring them to new tasks with minimal risk of overfitting and lower computational demand. This approach is particularly beneficial when adapting complex models to specific tasks where the availability of large labeled datasets may be limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're on the right track, and your observation about how the weights are handled in this scenario is insightful. Let me clarify how this works and why it's done this way.\n",
    "\n",
    "### How Pre-trained Models and Weights Work in Keras:\n",
    "\n",
    "1. **Model Loading Options**:\n",
    "    - When you load a model like InceptionV3 in Keras, you typically have a few options for the `weights` parameter:\n",
    "      - **`weights='imagenet'`**: Automatically loads weights pre-trained on the ImageNet dataset.\n",
    "      - **`weights=None'`**: Initializes the model without any weights, meaning all weights are set randomly.\n",
    "\n",
    "2. **Purpose of `include_top=False` and `weights=None`**:\n",
    "    - **`include_top=False`**: This excludes the dense layers at the top of the model, which are specific to the ImageNet classification task (1,000 classes). It's useful when you want to use the model as a feature extractor in transfer learning for a different task.\n",
    "    - **`weights=None`**: Starts the model with no weights. This might seem counterintuitive in transfer learning where you want to leverage pre-existing knowledge.\n",
    "\n",
    "3. **Loading Weights Manually**:\n",
    "    - After initializing the model with `weights=None`, the example explicitly loads a specific weight file with `pre_trained_model.load_weights(path)`.\n",
    "    - The weights file in this context (`inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5`) is specifically formatted to include only the weights for the convolutional base (i.e., no top dense layers). This file is tailored for use in transfer learning scenarios where the top layers will be replaced or are not relevant.\n",
    "    - By using this approach, the course makes the learning process explicit and instructional. It demonstrates how you can manually manage model weights, which is a crucial aspect of handling pre-trained models in different contexts.\n",
    "\n",
    "### Why Not Load Weights Automatically?\n",
    "\n",
    "- The manual process might be used for educational purposes to illustrate how you can control model configuration in a granular way. It shows you how to manipulate models beyond the standard configurations provided by Keras.\n",
    "- Alternatively, it could be due to the specific requirements of the dataset or task, where you might want to load a custom set of weights that are not the standard ImageNet weights or where you need to ensure the model structure aligns perfectly with the weights being loaded.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The `InceptionV3` model can indeed come with weights trained on ImageNet, but in the example you're working with, the initial setup with `weights=None` allows for a clear demonstration of how to load and manage weights manually.\n",
    "- This method is particularly educational and gives flexibility, showing you how to adapt the model for tasks that may require different configurations or custom weight files.\n",
    "- By loading the weights separately, it also ensures that you are using the convolutional base without the classification layers, tailored specifically to the needs of the transfer learning task at hand.\n",
    "\n",
    "This process might seem a bit complex initially, but it provides a strong foundation in understanding how to effectively leverage and customize pre-trained models in deep learning. If you have any more questions or need further clarification, feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C2_W3_Lab_1_transfer_learning.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W3/ungraded_labs/C2_W3_Lab_1_transfer_learning.ipynb",
     "timestamp": 1639668234563
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
