{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W3/ungraded_lab/C2_W3_Lab_1_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bT0to3TL2q7H"
   },
   "source": [
    "# Ungraded Lab: Transfer Learning\n",
    "\n",
    "In this lab, you will see how you can use a pre-trained model to achieve good results even with a small training dataset. This is called _transfer learning_ and you do this by leveraging the trained layers of an existing model and adding your own layers to fit your application. For example, you can:\n",
    "\n",
    "1. just get the convolution layers of one model\n",
    "2. attach some dense layers onto it\n",
    "3. train just the dense network\n",
    "4. evaluate the results\n",
    "\n",
    "Doing this will allow you to save time building your application because you will essentially skip weeks of training time of very deep networks. You will just use the features it has learned and tweak it for your dataset. Let's see how these are done in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvrr8pLRzJMV"
   },
   "source": [
    "**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running the notebook on your local machine might result in some of the code blocks throwing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-12slkPL6_JH"
   },
   "source": [
    "## Setup the pretrained model\n",
    "\n",
    "You will need to prepare pretrained model and configure the layers that you need. For this exercise, you will use the convolution layers of the [InceptionV3](https://arxiv.org/abs/1512.00567) architecture as your base model. To do that, you need to:\n",
    "\n",
    "1. Set the input shape to fit your application. In this case. set it to `150x150x3` as you've been doing in the last few labs.\n",
    "\n",
    "2. Pick and freeze the convolution layers to take advantage of the features it has learned already.\n",
    "\n",
    "3. Add dense layers which you will train.\n",
    "\n",
    "Let's see how to do these in the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VqhFEK2Y-PK"
   },
   "source": [
    "First, in preparing the input to the model, you want to fetch the pretrained weights of the `InceptionV3` model and remove the fully connected layer at the end because you will be replacing it later. You will also specify the input shape that your model will accept. Lastly, you want to freeze the weights of these layers because they have been trained already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "base_path = '../../../data/models/'\n",
    "file_name = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "path = os.path.join(base_path, file_name)\n",
    "url = 'https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'  # without the -O\n",
    "\n",
    "# ensure path exists\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# download file\n",
    "response = requests.get(url)\n",
    "with open(path, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "KsiBCpQ1VvPp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the weights file you downloaded into a variable\n",
    "#local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize the base model.\n",
    "# Set the input shape and remove the dense layers.\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, # Exclude final dense layers; used for feature extraction.\n",
    "                                weights = None)      # Do not load any pre-trained weights.\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "pre_trained_model.load_weights(path)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False  # Prevent the layers' weights from being updated during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y2rEnqFaa9k"
   },
   "source": [
    "You can see the summary of the model below. You can see that it is a very deep network. You can then select up to which point of the network you want to use. As Laurence showed in the exercise, you will use up to `mixed7` as your base model and add to that. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application. `mixed7` on the other hand will be more generalized and you can start with that for your application. After the exercise, feel free to modify and use other layers to see what the results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qeGP0Ust5kCR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_564 (Conv2D)            (None, 74, 74, 32)   864         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_564 (Batch  (None, 74, 74, 32)  96          ['conv2d_564[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_564 (Activation)    (None, 74, 74, 32)   0           ['batch_normalization_564[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_565 (Conv2D)            (None, 72, 72, 32)   9216        ['activation_564[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_565 (Batch  (None, 72, 72, 32)  96          ['conv2d_565[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_565 (Activation)    (None, 72, 72, 32)   0           ['batch_normalization_565[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_566 (Conv2D)            (None, 72, 72, 64)   18432       ['activation_565[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_566 (Batch  (None, 72, 72, 64)  192         ['conv2d_566[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_566 (Activation)    (None, 72, 72, 64)   0           ['batch_normalization_566[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooling2D  (None, 35, 35, 64)  0           ['activation_566[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_567 (Conv2D)            (None, 35, 35, 80)   5120        ['max_pooling2d_24[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_567 (Batch  (None, 35, 35, 80)  240         ['conv2d_567[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_567 (Activation)    (None, 35, 35, 80)   0           ['batch_normalization_567[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_568 (Conv2D)            (None, 33, 33, 192)  138240      ['activation_567[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_568 (Batch  (None, 33, 33, 192)  576        ['conv2d_568[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_568 (Activation)    (None, 33, 33, 192)  0           ['batch_normalization_568[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_25 (MaxPooling2D  (None, 16, 16, 192)  0          ['activation_568[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_572 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_572 (Batch  (None, 16, 16, 64)  192         ['conv2d_572[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_572 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_572[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_570 (Conv2D)            (None, 16, 16, 48)   9216        ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_573 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_572[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_570 (Batch  (None, 16, 16, 48)  144         ['conv2d_570[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_573 (Batch  (None, 16, 16, 96)  288         ['conv2d_573[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_570 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_570[0][0]']\n",
      "                                                                                                  \n",
      " activation_573 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_573[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_54 (AverageP  (None, 16, 16, 192)  0          ['max_pooling2d_25[0][0]']       \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_569 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_571 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_570[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_574 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_573[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_575 (Conv2D)            (None, 16, 16, 32)   6144        ['average_pooling2d_54[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_569 (Batch  (None, 16, 16, 64)  192         ['conv2d_569[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_571 (Batch  (None, 16, 16, 64)  192         ['conv2d_571[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_574 (Batch  (None, 16, 16, 96)  288         ['conv2d_574[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_575 (Batch  (None, 16, 16, 32)  96          ['conv2d_575[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_569 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_569[0][0]']\n",
      "                                                                                                  \n",
      " activation_571 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_571[0][0]']\n",
      "                                                                                                  \n",
      " activation_574 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_574[0][0]']\n",
      "                                                                                                  \n",
      " activation_575 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_575[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_569[0][0]',         \n",
      "                                                                  'activation_571[0][0]',         \n",
      "                                                                  'activation_574[0][0]',         \n",
      "                                                                  'activation_575[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_579 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_579 (Batch  (None, 16, 16, 64)  192         ['conv2d_579[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_579 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_579[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_577 (Conv2D)            (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_580 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_579[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_577 (Batch  (None, 16, 16, 48)  144         ['conv2d_577[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_580 (Batch  (None, 16, 16, 96)  288         ['conv2d_580[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_577 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_577[0][0]']\n",
      "                                                                                                  \n",
      " activation_580 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_580[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_55 (AverageP  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_576 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_578 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_577[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_581 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_580[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_582 (Conv2D)            (None, 16, 16, 64)   16384       ['average_pooling2d_55[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_576 (Batch  (None, 16, 16, 64)  192         ['conv2d_576[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_578 (Batch  (None, 16, 16, 64)  192         ['conv2d_578[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_581 (Batch  (None, 16, 16, 96)  288         ['conv2d_581[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_582 (Batch  (None, 16, 16, 64)  192         ['conv2d_582[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_576 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_576[0][0]']\n",
      "                                                                                                  \n",
      " activation_578 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_578[0][0]']\n",
      "                                                                                                  \n",
      " activation_581 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_581[0][0]']\n",
      "                                                                                                  \n",
      " activation_582 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_582[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_576[0][0]',         \n",
      "                                                                  'activation_578[0][0]',         \n",
      "                                                                  'activation_581[0][0]',         \n",
      "                                                                  'activation_582[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_586 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_586 (Batch  (None, 16, 16, 64)  192         ['conv2d_586[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_586 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_586[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_584 (Conv2D)            (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_587 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_586[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_584 (Batch  (None, 16, 16, 48)  144         ['conv2d_584[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_587 (Batch  (None, 16, 16, 96)  288         ['conv2d_587[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_584 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_584[0][0]']\n",
      "                                                                                                  \n",
      " activation_587 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_587[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_56 (AverageP  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_583 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_585 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_584[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_588 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_587[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_589 (Conv2D)            (None, 16, 16, 64)   18432       ['average_pooling2d_56[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_583 (Batch  (None, 16, 16, 64)  192         ['conv2d_583[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_585 (Batch  (None, 16, 16, 64)  192         ['conv2d_585[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_588 (Batch  (None, 16, 16, 96)  288         ['conv2d_588[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_589 (Batch  (None, 16, 16, 64)  192         ['conv2d_589[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_583 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_583[0][0]']\n",
      "                                                                                                  \n",
      " activation_585 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_585[0][0]']\n",
      "                                                                                                  \n",
      " activation_588 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_588[0][0]']\n",
      "                                                                                                  \n",
      " activation_589 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_589[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_583[0][0]',         \n",
      "                                                                  'activation_585[0][0]',         \n",
      "                                                                  'activation_588[0][0]',         \n",
      "                                                                  'activation_589[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_591 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_591 (Batch  (None, 16, 16, 64)  192         ['conv2d_591[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_591 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_591[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_592 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_591[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_592 (Batch  (None, 16, 16, 96)  288         ['conv2d_592[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_592 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_592[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_590 (Conv2D)            (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_593 (Conv2D)            (None, 7, 7, 96)     82944       ['activation_592[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_590 (Batch  (None, 7, 7, 384)   1152        ['conv2d_590[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_593 (Batch  (None, 7, 7, 96)    288         ['conv2d_593[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_590 (Activation)    (None, 7, 7, 384)    0           ['batch_normalization_590[0][0]']\n",
      "                                                                                                  \n",
      " activation_593 (Activation)    (None, 7, 7, 96)     0           ['batch_normalization_593[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooling2D  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_590[0][0]',         \n",
      "                                                                  'activation_593[0][0]',         \n",
      "                                                                  'max_pooling2d_26[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_598 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_598 (Batch  (None, 7, 7, 128)   384         ['conv2d_598[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_598 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_598[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_599 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_598[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_599 (Batch  (None, 7, 7, 128)   384         ['conv2d_599[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_599 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_599[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_595 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_600 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_599[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_595 (Batch  (None, 7, 7, 128)   384         ['conv2d_595[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_600 (Batch  (None, 7, 7, 128)   384         ['conv2d_600[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_595 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_595[0][0]']\n",
      "                                                                                                  \n",
      " activation_600 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_600[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_596 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_595[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_601 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_600[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_596 (Batch  (None, 7, 7, 128)   384         ['conv2d_596[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_601 (Batch  (None, 7, 7, 128)   384         ['conv2d_601[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_596 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_596[0][0]']\n",
      "                                                                                                  \n",
      " activation_601 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_601[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_57 (AverageP  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_594 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_597 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_596[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_602 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_601[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_603 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_57[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_594 (Batch  (None, 7, 7, 192)   576         ['conv2d_594[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_597 (Batch  (None, 7, 7, 192)   576         ['conv2d_597[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_602 (Batch  (None, 7, 7, 192)   576         ['conv2d_602[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_603 (Batch  (None, 7, 7, 192)   576         ['conv2d_603[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_594 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_594[0][0]']\n",
      "                                                                                                  \n",
      " activation_597 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_597[0][0]']\n",
      "                                                                                                  \n",
      " activation_602 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_602[0][0]']\n",
      "                                                                                                  \n",
      " activation_603 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_603[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_594[0][0]',         \n",
      "                                                                  'activation_597[0][0]',         \n",
      "                                                                  'activation_602[0][0]',         \n",
      "                                                                  'activation_603[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_608 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_608 (Batch  (None, 7, 7, 160)   480         ['conv2d_608[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_608 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_608[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_609 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_608[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_609 (Batch  (None, 7, 7, 160)   480         ['conv2d_609[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_609 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_609[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_605 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_610 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_609[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_605 (Batch  (None, 7, 7, 160)   480         ['conv2d_605[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_610 (Batch  (None, 7, 7, 160)   480         ['conv2d_610[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_605 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_605[0][0]']\n",
      "                                                                                                  \n",
      " activation_610 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_610[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_606 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_605[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_611 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_610[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_606 (Batch  (None, 7, 7, 160)   480         ['conv2d_606[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_611 (Batch  (None, 7, 7, 160)   480         ['conv2d_611[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_606 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_606[0][0]']\n",
      "                                                                                                  \n",
      " activation_611 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_611[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_58 (AverageP  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_604 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_607 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_606[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_612 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_611[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_613 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_58[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_604 (Batch  (None, 7, 7, 192)   576         ['conv2d_604[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_607 (Batch  (None, 7, 7, 192)   576         ['conv2d_607[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_612 (Batch  (None, 7, 7, 192)   576         ['conv2d_612[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_613 (Batch  (None, 7, 7, 192)   576         ['conv2d_613[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_604 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_604[0][0]']\n",
      "                                                                                                  \n",
      " activation_607 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_607[0][0]']\n",
      "                                                                                                  \n",
      " activation_612 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_612[0][0]']\n",
      "                                                                                                  \n",
      " activation_613 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_613[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_604[0][0]',         \n",
      "                                                                  'activation_607[0][0]',         \n",
      "                                                                  'activation_612[0][0]',         \n",
      "                                                                  'activation_613[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_618 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_618 (Batch  (None, 7, 7, 160)   480         ['conv2d_618[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_618 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_618[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_619 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_618[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_619 (Batch  (None, 7, 7, 160)   480         ['conv2d_619[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_619 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_619[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_615 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_620 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_619[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_615 (Batch  (None, 7, 7, 160)   480         ['conv2d_615[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_620 (Batch  (None, 7, 7, 160)   480         ['conv2d_620[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_615 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_615[0][0]']\n",
      "                                                                                                  \n",
      " activation_620 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_620[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_616 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_615[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_621 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_620[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_616 (Batch  (None, 7, 7, 160)   480         ['conv2d_616[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_621 (Batch  (None, 7, 7, 160)   480         ['conv2d_621[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_616 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_616[0][0]']\n",
      "                                                                                                  \n",
      " activation_621 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_621[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_59 (AverageP  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_614 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_617 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_616[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_622 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_621[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_623 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_59[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_614 (Batch  (None, 7, 7, 192)   576         ['conv2d_614[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_617 (Batch  (None, 7, 7, 192)   576         ['conv2d_617[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_622 (Batch  (None, 7, 7, 192)   576         ['conv2d_622[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_623 (Batch  (None, 7, 7, 192)   576         ['conv2d_623[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_614 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_614[0][0]']\n",
      "                                                                                                  \n",
      " activation_617 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_617[0][0]']\n",
      "                                                                                                  \n",
      " activation_622 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_622[0][0]']\n",
      "                                                                                                  \n",
      " activation_623 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_623[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_614[0][0]',         \n",
      "                                                                  'activation_617[0][0]',         \n",
      "                                                                  'activation_622[0][0]',         \n",
      "                                                                  'activation_623[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_628 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_628 (Batch  (None, 7, 7, 192)   576         ['conv2d_628[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_628 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_628[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_629 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_628[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_629 (Batch  (None, 7, 7, 192)   576         ['conv2d_629[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_629 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_629[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_625 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_630 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_629[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_625 (Batch  (None, 7, 7, 192)   576         ['conv2d_625[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_630 (Batch  (None, 7, 7, 192)   576         ['conv2d_630[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_625 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_625[0][0]']\n",
      "                                                                                                  \n",
      " activation_630 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_630[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_626 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_625[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_631 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_630[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_626 (Batch  (None, 7, 7, 192)   576         ['conv2d_626[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_631 (Batch  (None, 7, 7, 192)   576         ['conv2d_631[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_626 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_626[0][0]']\n",
      "                                                                                                  \n",
      " activation_631 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_631[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_60 (AverageP  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_624 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_627 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_626[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_632 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_631[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_633 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_60[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_624 (Batch  (None, 7, 7, 192)   576         ['conv2d_624[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_627 (Batch  (None, 7, 7, 192)   576         ['conv2d_627[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_632 (Batch  (None, 7, 7, 192)   576         ['conv2d_632[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_633 (Batch  (None, 7, 7, 192)   576         ['conv2d_633[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_624 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_624[0][0]']\n",
      "                                                                                                  \n",
      " activation_627 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_627[0][0]']\n",
      "                                                                                                  \n",
      " activation_632 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_632[0][0]']\n",
      "                                                                                                  \n",
      " activation_633 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_633[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_624[0][0]',         \n",
      "                                                                  'activation_627[0][0]',         \n",
      "                                                                  'activation_632[0][0]',         \n",
      "                                                                  'activation_633[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_636 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_636 (Batch  (None, 7, 7, 192)   576         ['conv2d_636[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_636 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_636[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_637 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_636[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_637 (Batch  (None, 7, 7, 192)   576         ['conv2d_637[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_637 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_637[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_634 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_638 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_637[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_634 (Batch  (None, 7, 7, 192)   576         ['conv2d_634[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_638 (Batch  (None, 7, 7, 192)   576         ['conv2d_638[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_634 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_634[0][0]']\n",
      "                                                                                                  \n",
      " activation_638 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_638[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_635 (Conv2D)            (None, 3, 3, 320)    552960      ['activation_634[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_639 (Conv2D)            (None, 3, 3, 192)    331776      ['activation_638[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_635 (Batch  (None, 3, 3, 320)   960         ['conv2d_635[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_639 (Batch  (None, 3, 3, 192)   576         ['conv2d_639[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_635 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_635[0][0]']\n",
      "                                                                                                  \n",
      " activation_639 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_639[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooling2D  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_635[0][0]',         \n",
      "                                                                  'activation_639[0][0]',         \n",
      "                                                                  'max_pooling2d_27[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_644 (Conv2D)            (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_644 (Batch  (None, 3, 3, 448)   1344        ['conv2d_644[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_644 (Activation)    (None, 3, 3, 448)    0           ['batch_normalization_644[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_641 (Conv2D)            (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_645 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_644[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_641 (Batch  (None, 3, 3, 384)   1152        ['conv2d_641[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_645 (Batch  (None, 3, 3, 384)   1152        ['conv2d_645[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_641 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_641[0][0]']\n",
      "                                                                                                  \n",
      " activation_645 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_645[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_642 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_641[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_643 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_641[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_646 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_645[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_647 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_645[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_61 (AverageP  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_640 (Conv2D)            (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_642 (Batch  (None, 3, 3, 384)   1152        ['conv2d_642[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_643 (Batch  (None, 3, 3, 384)   1152        ['conv2d_643[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_646 (Batch  (None, 3, 3, 384)   1152        ['conv2d_646[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_647 (Batch  (None, 3, 3, 384)   1152        ['conv2d_647[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_648 (Conv2D)            (None, 3, 3, 192)    245760      ['average_pooling2d_61[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_640 (Batch  (None, 3, 3, 320)   960         ['conv2d_640[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_642 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_642[0][0]']\n",
      "                                                                                                  \n",
      " activation_643 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_643[0][0]']\n",
      "                                                                                                  \n",
      " activation_646 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_646[0][0]']\n",
      "                                                                                                  \n",
      " activation_647 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_647[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_648 (Batch  (None, 3, 3, 192)   576         ['conv2d_648[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_640 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_640[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_642[0][0]',         \n",
      "                                                                  'activation_643[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 3, 3, 768)    0           ['activation_646[0][0]',         \n",
      "                                                                  'activation_647[0][0]']         \n",
      "                                                                                                  \n",
      " activation_648 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_648[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_640[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_12[0][0]',         \n",
      "                                                                  'activation_648[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_653 (Conv2D)            (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_653 (Batch  (None, 3, 3, 448)   1344        ['conv2d_653[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_653 (Activation)    (None, 3, 3, 448)    0           ['batch_normalization_653[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_650 (Conv2D)            (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_654 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_653[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_650 (Batch  (None, 3, 3, 384)   1152        ['conv2d_650[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_654 (Batch  (None, 3, 3, 384)   1152        ['conv2d_654[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_650 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_650[0][0]']\n",
      "                                                                                                  \n",
      " activation_654 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_654[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_651 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_650[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_652 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_650[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_655 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_654[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_656 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_654[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_62 (AverageP  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_649 (Conv2D)            (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_651 (Batch  (None, 3, 3, 384)   1152        ['conv2d_651[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_652 (Batch  (None, 3, 3, 384)   1152        ['conv2d_652[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_655 (Batch  (None, 3, 3, 384)   1152        ['conv2d_655[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_656 (Batch  (None, 3, 3, 384)   1152        ['conv2d_656[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_657 (Conv2D)            (None, 3, 3, 192)    393216      ['average_pooling2d_62[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_649 (Batch  (None, 3, 3, 320)   960         ['conv2d_649[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_651 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_651[0][0]']\n",
      "                                                                                                  \n",
      " activation_652 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_652[0][0]']\n",
      "                                                                                                  \n",
      " activation_655 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_655[0][0]']\n",
      "                                                                                                  \n",
      " activation_656 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_656[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_657 (Batch  (None, 3, 3, 192)   576         ['conv2d_657[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_649 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_649[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_651[0][0]',         \n",
      "                                                                  'activation_652[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 3, 3, 768)    0           ['activation_655[0][0]',         \n",
      "                                                                  'activation_656[0][0]']         \n",
      "                                                                                                  \n",
      " activation_657 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_657[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_649[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_13[0][0]',         \n",
      "                                                                  'activation_657[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "jDmGO9tg5iPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "# Choose `mixed7` as the last layer of your base model\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXT9SDMK7Ioa"
   },
   "source": [
    "## Add dense layers for your classifier\n",
    "\n",
    "Next, you will add dense layers to your model. These will be the layers that you will train and is tasked with recognizing cats and dogs. You will add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer as well to regularize the output and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_564 (Conv2D)            (None, 74, 74, 32)   864         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_564 (Batch  (None, 74, 74, 32)  96          ['conv2d_564[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_564 (Activation)    (None, 74, 74, 32)   0           ['batch_normalization_564[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_565 (Conv2D)            (None, 72, 72, 32)   9216        ['activation_564[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_565 (Batch  (None, 72, 72, 32)  96          ['conv2d_565[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_565 (Activation)    (None, 72, 72, 32)   0           ['batch_normalization_565[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_566 (Conv2D)            (None, 72, 72, 64)   18432       ['activation_565[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_566 (Batch  (None, 72, 72, 64)  192         ['conv2d_566[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_566 (Activation)    (None, 72, 72, 64)   0           ['batch_normalization_566[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooling2D  (None, 35, 35, 64)  0           ['activation_566[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_567 (Conv2D)            (None, 35, 35, 80)   5120        ['max_pooling2d_24[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_567 (Batch  (None, 35, 35, 80)  240         ['conv2d_567[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_567 (Activation)    (None, 35, 35, 80)   0           ['batch_normalization_567[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_568 (Conv2D)            (None, 33, 33, 192)  138240      ['activation_567[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_568 (Batch  (None, 33, 33, 192)  576        ['conv2d_568[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_568 (Activation)    (None, 33, 33, 192)  0           ['batch_normalization_568[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_25 (MaxPooling2D  (None, 16, 16, 192)  0          ['activation_568[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_572 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_572 (Batch  (None, 16, 16, 64)  192         ['conv2d_572[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_572 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_572[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_570 (Conv2D)            (None, 16, 16, 48)   9216        ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_573 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_572[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_570 (Batch  (None, 16, 16, 48)  144         ['conv2d_570[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_573 (Batch  (None, 16, 16, 96)  288         ['conv2d_573[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_570 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_570[0][0]']\n",
      "                                                                                                  \n",
      " activation_573 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_573[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_54 (AverageP  (None, 16, 16, 192)  0          ['max_pooling2d_25[0][0]']       \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_569 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_571 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_570[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_574 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_573[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_575 (Conv2D)            (None, 16, 16, 32)   6144        ['average_pooling2d_54[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_569 (Batch  (None, 16, 16, 64)  192         ['conv2d_569[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_571 (Batch  (None, 16, 16, 64)  192         ['conv2d_571[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_574 (Batch  (None, 16, 16, 96)  288         ['conv2d_574[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_575 (Batch  (None, 16, 16, 32)  96          ['conv2d_575[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_569 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_569[0][0]']\n",
      "                                                                                                  \n",
      " activation_571 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_571[0][0]']\n",
      "                                                                                                  \n",
      " activation_574 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_574[0][0]']\n",
      "                                                                                                  \n",
      " activation_575 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_575[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_569[0][0]',         \n",
      "                                                                  'activation_571[0][0]',         \n",
      "                                                                  'activation_574[0][0]',         \n",
      "                                                                  'activation_575[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_579 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_579 (Batch  (None, 16, 16, 64)  192         ['conv2d_579[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_579 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_579[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_577 (Conv2D)            (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_580 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_579[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_577 (Batch  (None, 16, 16, 48)  144         ['conv2d_577[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_580 (Batch  (None, 16, 16, 96)  288         ['conv2d_580[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_577 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_577[0][0]']\n",
      "                                                                                                  \n",
      " activation_580 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_580[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_55 (AverageP  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_576 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_578 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_577[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_581 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_580[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_582 (Conv2D)            (None, 16, 16, 64)   16384       ['average_pooling2d_55[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_576 (Batch  (None, 16, 16, 64)  192         ['conv2d_576[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_578 (Batch  (None, 16, 16, 64)  192         ['conv2d_578[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_581 (Batch  (None, 16, 16, 96)  288         ['conv2d_581[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_582 (Batch  (None, 16, 16, 64)  192         ['conv2d_582[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_576 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_576[0][0]']\n",
      "                                                                                                  \n",
      " activation_578 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_578[0][0]']\n",
      "                                                                                                  \n",
      " activation_581 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_581[0][0]']\n",
      "                                                                                                  \n",
      " activation_582 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_582[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_576[0][0]',         \n",
      "                                                                  'activation_578[0][0]',         \n",
      "                                                                  'activation_581[0][0]',         \n",
      "                                                                  'activation_582[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_586 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_586 (Batch  (None, 16, 16, 64)  192         ['conv2d_586[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_586 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_586[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_584 (Conv2D)            (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_587 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_586[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_584 (Batch  (None, 16, 16, 48)  144         ['conv2d_584[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_587 (Batch  (None, 16, 16, 96)  288         ['conv2d_587[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_584 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_584[0][0]']\n",
      "                                                                                                  \n",
      " activation_587 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_587[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_56 (AverageP  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_583 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_585 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_584[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_588 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_587[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_589 (Conv2D)            (None, 16, 16, 64)   18432       ['average_pooling2d_56[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_583 (Batch  (None, 16, 16, 64)  192         ['conv2d_583[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_585 (Batch  (None, 16, 16, 64)  192         ['conv2d_585[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_588 (Batch  (None, 16, 16, 96)  288         ['conv2d_588[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_589 (Batch  (None, 16, 16, 64)  192         ['conv2d_589[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_583 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_583[0][0]']\n",
      "                                                                                                  \n",
      " activation_585 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_585[0][0]']\n",
      "                                                                                                  \n",
      " activation_588 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_588[0][0]']\n",
      "                                                                                                  \n",
      " activation_589 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_589[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_583[0][0]',         \n",
      "                                                                  'activation_585[0][0]',         \n",
      "                                                                  'activation_588[0][0]',         \n",
      "                                                                  'activation_589[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_591 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_591 (Batch  (None, 16, 16, 64)  192         ['conv2d_591[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_591 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_591[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_592 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_591[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_592 (Batch  (None, 16, 16, 96)  288         ['conv2d_592[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_592 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_592[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_590 (Conv2D)            (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_593 (Conv2D)            (None, 7, 7, 96)     82944       ['activation_592[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_590 (Batch  (None, 7, 7, 384)   1152        ['conv2d_590[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_593 (Batch  (None, 7, 7, 96)    288         ['conv2d_593[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_590 (Activation)    (None, 7, 7, 384)    0           ['batch_normalization_590[0][0]']\n",
      "                                                                                                  \n",
      " activation_593 (Activation)    (None, 7, 7, 96)     0           ['batch_normalization_593[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooling2D  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_590[0][0]',         \n",
      "                                                                  'activation_593[0][0]',         \n",
      "                                                                  'max_pooling2d_26[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_598 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_598 (Batch  (None, 7, 7, 128)   384         ['conv2d_598[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_598 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_598[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_599 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_598[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_599 (Batch  (None, 7, 7, 128)   384         ['conv2d_599[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_599 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_599[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_595 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_600 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_599[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_595 (Batch  (None, 7, 7, 128)   384         ['conv2d_595[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_600 (Batch  (None, 7, 7, 128)   384         ['conv2d_600[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_595 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_595[0][0]']\n",
      "                                                                                                  \n",
      " activation_600 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_600[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_596 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_595[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_601 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_600[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_596 (Batch  (None, 7, 7, 128)   384         ['conv2d_596[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_601 (Batch  (None, 7, 7, 128)   384         ['conv2d_601[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_596 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_596[0][0]']\n",
      "                                                                                                  \n",
      " activation_601 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_601[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_57 (AverageP  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_594 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_597 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_596[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_602 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_601[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_603 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_57[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_594 (Batch  (None, 7, 7, 192)   576         ['conv2d_594[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_597 (Batch  (None, 7, 7, 192)   576         ['conv2d_597[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_602 (Batch  (None, 7, 7, 192)   576         ['conv2d_602[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_603 (Batch  (None, 7, 7, 192)   576         ['conv2d_603[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_594 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_594[0][0]']\n",
      "                                                                                                  \n",
      " activation_597 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_597[0][0]']\n",
      "                                                                                                  \n",
      " activation_602 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_602[0][0]']\n",
      "                                                                                                  \n",
      " activation_603 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_603[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_594[0][0]',         \n",
      "                                                                  'activation_597[0][0]',         \n",
      "                                                                  'activation_602[0][0]',         \n",
      "                                                                  'activation_603[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_608 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_608 (Batch  (None, 7, 7, 160)   480         ['conv2d_608[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_608 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_608[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_609 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_608[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_609 (Batch  (None, 7, 7, 160)   480         ['conv2d_609[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_609 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_609[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_605 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_610 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_609[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_605 (Batch  (None, 7, 7, 160)   480         ['conv2d_605[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_610 (Batch  (None, 7, 7, 160)   480         ['conv2d_610[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_605 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_605[0][0]']\n",
      "                                                                                                  \n",
      " activation_610 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_610[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_606 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_605[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_611 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_610[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_606 (Batch  (None, 7, 7, 160)   480         ['conv2d_606[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_611 (Batch  (None, 7, 7, 160)   480         ['conv2d_611[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_606 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_606[0][0]']\n",
      "                                                                                                  \n",
      " activation_611 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_611[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_58 (AverageP  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_604 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_607 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_606[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_612 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_611[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_613 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_58[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_604 (Batch  (None, 7, 7, 192)   576         ['conv2d_604[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_607 (Batch  (None, 7, 7, 192)   576         ['conv2d_607[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_612 (Batch  (None, 7, 7, 192)   576         ['conv2d_612[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_613 (Batch  (None, 7, 7, 192)   576         ['conv2d_613[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_604 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_604[0][0]']\n",
      "                                                                                                  \n",
      " activation_607 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_607[0][0]']\n",
      "                                                                                                  \n",
      " activation_612 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_612[0][0]']\n",
      "                                                                                                  \n",
      " activation_613 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_613[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_604[0][0]',         \n",
      "                                                                  'activation_607[0][0]',         \n",
      "                                                                  'activation_612[0][0]',         \n",
      "                                                                  'activation_613[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_618 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_618 (Batch  (None, 7, 7, 160)   480         ['conv2d_618[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_618 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_618[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_619 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_618[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_619 (Batch  (None, 7, 7, 160)   480         ['conv2d_619[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_619 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_619[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_615 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_620 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_619[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_615 (Batch  (None, 7, 7, 160)   480         ['conv2d_615[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_620 (Batch  (None, 7, 7, 160)   480         ['conv2d_620[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_615 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_615[0][0]']\n",
      "                                                                                                  \n",
      " activation_620 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_620[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_616 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_615[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_621 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_620[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_616 (Batch  (None, 7, 7, 160)   480         ['conv2d_616[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_621 (Batch  (None, 7, 7, 160)   480         ['conv2d_621[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_616 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_616[0][0]']\n",
      "                                                                                                  \n",
      " activation_621 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_621[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_59 (AverageP  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_614 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_617 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_616[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_622 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_621[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_623 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_59[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_614 (Batch  (None, 7, 7, 192)   576         ['conv2d_614[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_617 (Batch  (None, 7, 7, 192)   576         ['conv2d_617[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_622 (Batch  (None, 7, 7, 192)   576         ['conv2d_622[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_623 (Batch  (None, 7, 7, 192)   576         ['conv2d_623[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_614 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_614[0][0]']\n",
      "                                                                                                  \n",
      " activation_617 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_617[0][0]']\n",
      "                                                                                                  \n",
      " activation_622 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_622[0][0]']\n",
      "                                                                                                  \n",
      " activation_623 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_623[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_614[0][0]',         \n",
      "                                                                  'activation_617[0][0]',         \n",
      "                                                                  'activation_622[0][0]',         \n",
      "                                                                  'activation_623[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_628 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_628 (Batch  (None, 7, 7, 192)   576         ['conv2d_628[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_628 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_628[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_629 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_628[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_629 (Batch  (None, 7, 7, 192)   576         ['conv2d_629[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_629 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_629[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_625 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_630 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_629[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_625 (Batch  (None, 7, 7, 192)   576         ['conv2d_625[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_630 (Batch  (None, 7, 7, 192)   576         ['conv2d_630[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_625 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_625[0][0]']\n",
      "                                                                                                  \n",
      " activation_630 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_630[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_626 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_625[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_631 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_630[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_626 (Batch  (None, 7, 7, 192)   576         ['conv2d_626[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_631 (Batch  (None, 7, 7, 192)   576         ['conv2d_631[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_626 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_626[0][0]']\n",
      "                                                                                                  \n",
      " activation_631 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_631[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_60 (AverageP  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_624 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_627 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_626[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_632 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_631[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_633 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_60[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_624 (Batch  (None, 7, 7, 192)   576         ['conv2d_624[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_627 (Batch  (None, 7, 7, 192)   576         ['conv2d_627[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_632 (Batch  (None, 7, 7, 192)   576         ['conv2d_632[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_633 (Batch  (None, 7, 7, 192)   576         ['conv2d_633[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_624 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_624[0][0]']\n",
      "                                                                                                  \n",
      " activation_627 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_627[0][0]']\n",
      "                                                                                                  \n",
      " activation_632 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_632[0][0]']\n",
      "                                                                                                  \n",
      " activation_633 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_633[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_624[0][0]',         \n",
      "                                                                  'activation_627[0][0]',         \n",
      "                                                                  'activation_632[0][0]',         \n",
      "                                                                  'activation_633[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 37632)        0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1024)         38536192    ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 1024)         0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            1025        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "# Append the dense network to the base model\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "# Print the model summary. See your dense network connected at the end.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "SAwTTkWr56uC"
   },
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYLGw_RO7Z_X"
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "Now you will prepare the dataset. This is basically the same code as the one you used in the data augmentation lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "O4s8HckqGlnb"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# !wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: c:\\wagon\\code\\tensorflow-1-public\\data\n"
     ]
    }
   ],
   "source": [
    "# Code that works locally\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "url = 'https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip'\n",
    "\n",
    "# Path to save the downloaded file\n",
    "base_path = '../../../data'\n",
    "file_name = 'cats_and_dogs_filtered.zip'\n",
    "local_zip = os.path.join(base_path, file_name)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open(local_zip, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(local_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(base_path)\n",
    "\n",
    "# Delete zip file\n",
    "os.remove(local_zip)\n",
    "\n",
    "# Check if files are extracted\n",
    "print(f\"Files extracted to: {os.path.abspath(base_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "WOV8jON3c3Jv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Extract the archive\n",
    "# zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "# zip_ref.extractall(\"tmp/\")\n",
    "# zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "#base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "base_dir = os.path.join(base_path, 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') \n",
    "\n",
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') \n",
    "\n",
    "# Directory with validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') \n",
    "\n",
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m3S6AZb7h-B"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "With that, you can now train the model. You will do 20 epochs and plot the results afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 - 24s - loss: 0.3347 - accuracy: 0.8710 - val_loss: 0.0985 - val_accuracy: 0.9570 - 24s/epoch - 236ms/step\n",
      "Epoch 2/20\n",
      "100/100 - 10s - loss: 0.2105 - accuracy: 0.9210 - val_loss: 0.1196 - val_accuracy: 0.9550 - 10s/epoch - 98ms/step\n",
      "Epoch 3/20\n",
      "100/100 - 10s - loss: 0.1954 - accuracy: 0.9320 - val_loss: 0.1658 - val_accuracy: 0.9440 - 10s/epoch - 97ms/step\n",
      "Epoch 4/20\n",
      "100/100 - 10s - loss: 0.2080 - accuracy: 0.9215 - val_loss: 0.1265 - val_accuracy: 0.9610 - 10s/epoch - 97ms/step\n",
      "Epoch 5/20\n",
      "100/100 - 10s - loss: 0.2087 - accuracy: 0.9300 - val_loss: 0.1098 - val_accuracy: 0.9640 - 10s/epoch - 97ms/step\n",
      "Epoch 6/20\n",
      "100/100 - 10s - loss: 0.1578 - accuracy: 0.9420 - val_loss: 0.0884 - val_accuracy: 0.9660 - 10s/epoch - 98ms/step\n",
      "Epoch 7/20\n",
      "100/100 - 10s - loss: 0.1744 - accuracy: 0.9370 - val_loss: 0.0925 - val_accuracy: 0.9650 - 10s/epoch - 98ms/step\n",
      "Epoch 8/20\n",
      "100/100 - 10s - loss: 0.1659 - accuracy: 0.9400 - val_loss: 0.1087 - val_accuracy: 0.9700 - 10s/epoch - 97ms/step\n",
      "Epoch 9/20\n",
      "100/100 - 10s - loss: 0.1630 - accuracy: 0.9440 - val_loss: 0.1119 - val_accuracy: 0.9690 - 10s/epoch - 96ms/step\n",
      "Epoch 10/20\n",
      "100/100 - 10s - loss: 0.1789 - accuracy: 0.9415 - val_loss: 0.1695 - val_accuracy: 0.9560 - 10s/epoch - 97ms/step\n",
      "Epoch 11/20\n",
      "100/100 - 10s - loss: 0.1712 - accuracy: 0.9475 - val_loss: 0.1537 - val_accuracy: 0.9490 - 10s/epoch - 95ms/step\n",
      "Epoch 12/20\n",
      "100/100 - 10s - loss: 0.1452 - accuracy: 0.9435 - val_loss: 0.0974 - val_accuracy: 0.9710 - 10s/epoch - 97ms/step\n",
      "Epoch 13/20\n",
      "100/100 - 10s - loss: 0.1506 - accuracy: 0.9490 - val_loss: 0.1152 - val_accuracy: 0.9660 - 10s/epoch - 96ms/step\n",
      "Epoch 14/20\n",
      "100/100 - 10s - loss: 0.1602 - accuracy: 0.9475 - val_loss: 0.1203 - val_accuracy: 0.9680 - 10s/epoch - 96ms/step\n",
      "Epoch 15/20\n",
      "100/100 - 10s - loss: 0.1377 - accuracy: 0.9515 - val_loss: 0.1007 - val_accuracy: 0.9730 - 10s/epoch - 96ms/step\n",
      "Epoch 16/20\n",
      "100/100 - 10s - loss: 0.1458 - accuracy: 0.9460 - val_loss: 0.1006 - val_accuracy: 0.9730 - 10s/epoch - 96ms/step\n",
      "Epoch 17/20\n",
      "100/100 - 10s - loss: 0.1439 - accuracy: 0.9495 - val_loss: 0.0952 - val_accuracy: 0.9720 - 10s/epoch - 96ms/step\n",
      "Epoch 18/20\n",
      "100/100 - 10s - loss: 0.1219 - accuracy: 0.9585 - val_loss: 0.0953 - val_accuracy: 0.9710 - 10s/epoch - 98ms/step\n",
      "Epoch 19/20\n",
      "100/100 - 10s - loss: 0.1343 - accuracy: 0.9585 - val_loss: 0.1387 - val_accuracy: 0.9630 - 10s/epoch - 97ms/step\n",
      "Epoch 20/20\n",
      "100/100 - 10s - loss: 0.1220 - accuracy: 0.9575 - val_loss: 0.0994 - val_accuracy: 0.9660 - 10s/epoch - 99ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with freezing layers\n",
    "\n",
    "Epoch 1/20\n",
    "100/100 - 24s - loss: 0.3438 - accuracy: 0.8690 - val_loss: 0.2176 - val_accuracy: 0.9180 - 24s/epoch - 239ms/step\n",
    "Epoch 2/20\n",
    "100/100 - 10s - loss: 0.2201 - accuracy: 0.9145 - val_loss: 0.1175 - val_accuracy: 0.9610 - 10s/epoch - 99ms/step\n",
    "Epoch 3/20\n",
    "100/100 - 9s - loss: 0.2090 - accuracy: 0.9170 - val_loss: 0.1130 - val_accuracy: 0.9640 - 9s/epoch - 94ms/step\n",
    "Epoch 4/20\n",
    "100/100 - 9s - loss: 0.1926 - accuracy: 0.9270 - val_loss: 0.1003 - val_accuracy: 0.9680 - 9s/epoch - 94ms/step\n",
    "Epoch 5/20\n",
    "100/100 - 9s - loss: 0.1868 - accuracy: 0.9320 - val_loss: 0.1282 - val_accuracy: 0.9610 - 9s/epoch - 93ms/step\n",
    "Epoch 6/20\n",
    "100/100 - 9s - loss: 0.1865 - accuracy: 0.9390 - val_loss: 0.1130 - val_accuracy: 0.9650 - 9s/epoch - 95ms/step\n",
    "Epoch 7/20\n",
    "100/100 - 9s - loss: 0.1937 - accuracy: 0.9305 - val_loss: 0.0969 - val_accuracy: 0.9670 - 9s/epoch - 94ms/step\n",
    "Epoch 8/20\n",
    "100/100 - 10s - loss: 0.1541 - accuracy: 0.9435 - val_loss: 0.1230 - val_accuracy: 0.9610 - 10s/epoch - 97ms/step\n",
    "Epoch 9/20\n",
    "100/100 - 10s - loss: 0.1572 - accuracy: 0.9500 - val_loss: 0.0922 - val_accuracy: 0.9700 - 10s/epoch - 98ms/step\n",
    "Epoch 10/20\n",
    "100/100 - 10s - loss: 0.1650 - accuracy: 0.9465 - val_loss: 0.1333 - val_accuracy: 0.9620 - 10s/epoch - 99ms/step\n",
    "Epoch 11/20\n",
    "100/100 - 10s - loss: 0.1358 - accuracy: 0.9495 - val_loss: 0.1235 - val_accuracy: 0.9660 - 10s/epoch - 96ms/step\n",
    "Epoch 12/20\n",
    "100/100 - 10s - loss: 0.1737 - accuracy: 0.9450 - val_loss: 0.1340 - val_accuracy: 0.9520 - 10s/epoch - 95ms/step\n",
    "Epoch 13/20\n",
    "100/100 - 9s - loss: 0.1276 - accuracy: 0.9515 - val_loss: 0.1083 - val_accuracy: 0.9690 - 9s/epoch - 94ms/step\n",
    "Epoch 14/20\n",
    "100/100 - 10s - loss: 0.1498 - accuracy: 0.9430 - val_loss: 0.1150 - val_accuracy: 0.9640 - 10s/epoch - 96ms/step\n",
    "Epoch 15/20\n",
    "100/100 - 10s - loss: 0.1516 - accuracy: 0.9525 - val_loss: 0.1084 - val_accuracy: 0.9690 - 10s/epoch - 96ms/step\n",
    "Epoch 16/20\n",
    "100/100 - 10s - loss: 0.1572 - accuracy: 0.9470 - val_loss: 0.1588 - val_accuracy: 0.9540 - 10s/epoch - 98ms/step\n",
    "Epoch 17/20\n",
    "100/100 - 10s - loss: 0.1427 - accuracy: 0.9490 - val_loss: 0.1170 - val_accuracy: 0.9700 - 10s/epoch - 98ms/step\n",
    "Epoch 18/20\n",
    "100/100 - 10s - loss: 0.1292 - accuracy: 0.9580 - val_loss: 0.1466 - val_accuracy: 0.9620 - 10s/epoch - 97ms/step\n",
    "Epoch 19/20\n",
    "100/100 - 9s - loss: 0.1071 - accuracy: 0.9555 - val_loss: 0.1243 - val_accuracy: 0.9670 - 9s/epoch - 95ms/step\n",
    "Epoch 20/20\n",
    "100/100 - 9s - loss: 0.1301 - accuracy: 0.9550 - val_loss: 0.1319 - val_accuracy: 0.9630 - 9s/epoch - 94ms/step\n",
    "\n",
    "\n",
    "without freezing layers\n",
    "\n",
    "Epoch 1/20\n",
    "100/100 - 32s - loss: 0.3697 - accuracy: 0.8400 - val_loss: 0.3595 - val_accuracy: 0.9140 - 32s/epoch - 315ms/step\n",
    "Epoch 2/20\n",
    "100/100 - 10s - loss: 0.2227 - accuracy: 0.9080 - val_loss: 0.2001 - val_accuracy: 0.9480 - 10s/epoch - 99ms/step\n",
    "Epoch 3/20\n",
    "100/100 - 10s - loss: 0.1765 - accuracy: 0.9345 - val_loss: 0.2188 - val_accuracy: 0.9580 - 10s/epoch - 100ms/step\n",
    "Epoch 4/20\n",
    "100/100 - 10s - loss: 0.1552 - accuracy: 0.9380 - val_loss: 0.7529 - val_accuracy: 0.9250 - 10s/epoch - 99ms/step\n",
    "Epoch 5/20\n",
    "100/100 - 10s - loss: 0.1342 - accuracy: 0.9515 - val_loss: 0.3002 - val_accuracy: 0.9640 - 10s/epoch - 101ms/step\n",
    "Epoch 6/20\n",
    "100/100 - 10s - loss: 0.1205 - accuracy: 0.9610 - val_loss: 0.2677 - val_accuracy: 0.9590 - 10s/epoch - 100ms/step\n",
    "Epoch 7/20\n",
    "100/100 - 10s - loss: 0.1413 - accuracy: 0.9605 - val_loss: 0.7452 - val_accuracy: 0.9580 - 10s/epoch - 101ms/step\n",
    "Epoch 8/20\n",
    "100/100 - 10s - loss: 0.0946 - accuracy: 0.9690 - val_loss: 0.3574 - val_accuracy: 0.9550 - 10s/epoch - 99ms/step\n",
    "Epoch 9/20\n",
    "100/100 - 10s - loss: 0.1359 - accuracy: 0.9625 - val_loss: 0.6323 - val_accuracy: 0.9520 - 10s/epoch - 100ms/step\n",
    "Epoch 10/20\n",
    "100/100 - 10s - loss: 0.1011 - accuracy: 0.9725 - val_loss: 0.7085 - val_accuracy: 0.9610 - 10s/epoch - 100ms/step\n",
    "Epoch 11/20\n",
    "100/100 - 10s - loss: 0.0875 - accuracy: 0.9700 - val_loss: 0.3422 - val_accuracy: 0.9660 - 10s/epoch - 101ms/step\n",
    "Epoch 12/20\n",
    "100/100 - 10s - loss: 0.0871 - accuracy: 0.9725 - val_loss: 0.3484 - val_accuracy: 0.9540 - 10s/epoch - 100ms/step\n",
    "Epoch 13/20\n",
    "100/100 - 10s - loss: 0.0971 - accuracy: 0.9745 - val_loss: 1.1989 - val_accuracy: 0.9030 - 10s/epoch - 99ms/step\n",
    "Epoch 14/20\n",
    "100/100 - 10s - loss: 0.0680 - accuracy: 0.9820 - val_loss: 0.2448 - val_accuracy: 0.9580 - 10s/epoch - 99ms/step\n",
    "Epoch 15/20\n",
    "100/100 - 10s - loss: 0.0799 - accuracy: 0.9735 - val_loss: 0.3434 - val_accuracy: 0.9670 - 10s/epoch - 97ms/step\n",
    "Epoch 16/20\n",
    "100/100 - 10s - loss: 0.0613 - accuracy: 0.9815 - val_loss: 13.4375 - val_accuracy: 0.9570 - 10s/epoch - 95ms/step\n",
    "Epoch 17/20\n",
    "100/100 - 10s - loss: 0.0754 - accuracy: 0.9785 - val_loss: 5.5575 - val_accuracy: 0.9570 - 10s/epoch - 95ms/step\n",
    "Epoch 18/20\n",
    "100/100 - 9s - loss: 0.0520 - accuracy: 0.9805 - val_loss: 0.5496 - val_accuracy: 0.9730 - 9s/epoch - 95ms/step\n",
    "Epoch 19/20\n",
    "100/100 - 10s - loss: 0.0935 - accuracy: 0.9815 - val_loss: 0.7395 - val_accuracy: 0.9600 - 10s/epoch - 96ms/step\n",
    "Epoch 20/20\n",
    "100/100 - 10s - loss: 0.0725 - accuracy: 0.9800 - val_loss: 0.9159 - val_accuracy: 0.9600 - 10s/epoch - 97ms/step\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwcB2bPj7lIx"
   },
   "source": [
    "## Evaluate the results\n",
    "\n",
    "You will use the same code to plot the results. As you can see, the validation accuracy is also trending upwards as your training accuracy improves. This is a good sign that your model is no longer overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scenario described by Andrew Ng's Coursera course, using `include_top = False` and `weights = None` together is actually very strategic and not redundant when followed by loading specific pretrained weights (`weights=path`) and freezing the layers. This approach combines several techniques to leverage a pre-trained model effectively for a new, related task through transfer learning. Lets break down the steps and the rationale behind each:\n",
    "\n",
    "### Step-by-Step Analysis\n",
    "\n",
    "1. **Setting `include_top = False`**:\n",
    "    - This setting is used to remove the original top layers (usually dense layers) that were specific to the classification tasks for which the model was initially trained (like the 1000-class prediction in ImageNet).\n",
    "    - It allows you to replace these with layers that are better suited to your specific task, which in this context involves classifying images as either cats or dogs.\n",
    "\n",
    "2. **Setting `weights = None`**:\n",
    "    - Initially, this configuration specifies that the model should not automatically load the default pretrained weights at the time of initialization.\n",
    "    - This gives you control over which weights the model starts with, allowing for more flexibility, especially if you plan to load a different set of weights or modify the initialization in some way.\n",
    "\n",
    "3. **Loading Specific Pretrained Weights**:\n",
    "    - After initializing the model with `weights = None`, the course instructs to manually load pretrained weights with `pre_trained_model.load_weights(path)`.\n",
    "    - These weights are specifically the convolutional base of InceptionV3 without the top layers (`_notop`), tailored for feature extraction rather than for a specific classification task.\n",
    "    - This step ensures that you're using a robust feature extractor trained on a broad dataset like ImageNet, but without the final classification layers that don't pertain to your task.\n",
    "\n",
    "4. **Freezing the Convolutional Base**:\n",
    "    - The next step is to freeze the layers of this model by setting `layer.trainable = False`. This is crucial because it preserves the generic features these layers have learned, which are generally applicable to a wide range of image recognition tasks.\n",
    "    - Freezing prevents the pretrained weights from being updated during training. This is important when your dataset is relatively small or not diverse enough to retrain a deep network without overfitting.\n",
    "\n",
    "5. **Adding Custom Dense Layers**:\n",
    "    - On top of the frozen convolutional base, new trainable layers are added. These layers are designed to learn features specific to the new dataset (cats and dogs in this example).\n",
    "    - This approach allows for customization where the new data's specific features dictate the learning in these top layers, while the broad features extracted from the generic dataset are retained in the frozen layers.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This methodology is a classic example of transfer learning, where you take a pre-trained model, repurpose the feature-extracting layers, and then train a new classifier on top for a different but related task. Its efficient because:\n",
    "- **Speed**: You skip the time-consuming and computationally expensive process of training the convolutional layers from scratch.\n",
    "- **Performance**: You leverage the advanced feature-detecting capabilities of a model trained on a much larger dataset.\n",
    "- **Resource Management**: Its resource-efficient, requiring less data and computational power to achieve high accuracy.\n",
    "\n",
    "In essence, the `weights=None` initially followed by loading specific weights and freezing layers is a deliberate strategy to harness the strength of pre-existing models while tailoring them to new tasks with minimal risk of overfitting and lower computational demand. This approach is particularly beneficial when adapting complex models to specific tasks where the availability of large labeled datasets may be limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're on the right track, and your observation about how the weights are handled in this scenario is insightful. Let me clarify how this works and why it's done this way.\n",
    "\n",
    "### How Pre-trained Models and Weights Work in Keras:\n",
    "\n",
    "1. **Model Loading Options**:\n",
    "    - When you load a model like InceptionV3 in Keras, you typically have a few options for the `weights` parameter:\n",
    "      - **`weights='imagenet'`**: Automatically loads weights pre-trained on the ImageNet dataset.\n",
    "      - **`weights=None'`**: Initializes the model without any weights, meaning all weights are set randomly.\n",
    "\n",
    "2. **Purpose of `include_top=False` and `weights=None`**:\n",
    "    - **`include_top=False`**: This excludes the dense layers at the top of the model, which are specific to the ImageNet classification task (1,000 classes). It's useful when you want to use the model as a feature extractor in transfer learning for a different task.\n",
    "    - **`weights=None`**: Starts the model with no weights. This might seem counterintuitive in transfer learning where you want to leverage pre-existing knowledge.\n",
    "\n",
    "3. **Loading Weights Manually**:\n",
    "    - After initializing the model with `weights=None`, the example explicitly loads a specific weight file with `pre_trained_model.load_weights(path)`.\n",
    "    - The weights file in this context (`inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5`) is specifically formatted to include only the weights for the convolutional base (i.e., no top dense layers). This file is tailored for use in transfer learning scenarios where the top layers will be replaced or are not relevant.\n",
    "    - By using this approach, the course makes the learning process explicit and instructional. It demonstrates how you can manually manage model weights, which is a crucial aspect of handling pre-trained models in different contexts.\n",
    "\n",
    "### Why Not Load Weights Automatically?\n",
    "\n",
    "- The manual process might be used for educational purposes to illustrate how you can control model configuration in a granular way. It shows you how to manipulate models beyond the standard configurations provided by Keras.\n",
    "- Alternatively, it could be due to the specific requirements of the dataset or task, where you might want to load a custom set of weights that are not the standard ImageNet weights or where you need to ensure the model structure aligns perfectly with the weights being loaded.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The `InceptionV3` model can indeed come with weights trained on ImageNet, but in the example you're working with, the initial setup with `weights=None` allows for a clear demonstration of how to load and manage weights manually.\n",
    "- This method is particularly educational and gives flexibility, showing you how to adapt the model for tasks that may require different configurations or custom weight files.\n",
    "- By loading the weights separately, it also ensures that you are using the convolutional base without the classification layers, tailored specifically to the needs of the transfer learning task at hand.\n",
    "\n",
    "This process might seem a bit complex initially, but it provides a strong foundation in understanding how to effectively leverage and customize pre-trained models in deep learning. If you have any more questions or need further clarification, feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C2_W3_Lab_1_transfer_learning.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W3/ungraded_labs/C2_W3_Lab_1_transfer_learning.ipynb",
     "timestamp": 1639668234563
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
